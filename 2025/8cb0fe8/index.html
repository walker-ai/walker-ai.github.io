<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>推理引擎请求调度优化 - yitao's Blog</title><meta name=author content="yitao">
<meta name=description content="yitao的学习笔记"><meta name=keywords content='Blog,Blockchain,Book,Movie,Life,Journey'><meta itemprop=name content="推理引擎请求调度优化"><meta itemprop=description content="yitao的学习笔记"><meta itemprop=datePublished content="2025-08-24T11:36:09+08:00"><meta itemprop=dateModified content="2025-08-24T11:36:09+08:00"><meta itemprop=wordCount content="3461"><meta itemprop=image content="https://yitaonote.com/logo.png"><meta itemprop=keywords content="推理优化"><meta property="og:url" content="https://yitaonote.com/2025/8cb0fe8/"><meta property="og:site_name" content="yitao's Blog"><meta property="og:title" content="推理引擎请求调度优化"><meta property="og:description" content="yitao的学习笔记"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-08-24T11:36:09+08:00"><meta property="article:modified_time" content="2025-08-24T11:36:09+08:00"><meta property="og:image" content="https://yitaonote.com/logo.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://yitaonote.com/logo.png"><meta name=twitter:title content="推理引擎请求调度优化"><meta name=twitter:description content="yitao的学习笔记"><meta name=application-name content="yitao's Blog"><meta name=apple-mobile-web-app-title content="yitao's Blog"><meta name=theme-color data-light=#f8f8f8 data-dark=#252627 content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=canonical type=text/html href=https://yitaonote.com/2025/8cb0fe8/ title="推理引擎请求调度优化 - yitao's Blog"><link rel=prev type=text/html href=https://yitaonote.com/2025/34980c2/ title=GPU及CUDA基本概念><link rel=next type=text/html href=https://yitaonote.com/2025/a793bc7/ title=量化><link rel=alternate type=text/markdown href=https://yitaonote.com/2025/8cb0fe8/index.md title="推理引擎请求调度优化 - yitao's Blog"><link rel=stylesheet href=/css/style.min.css><link rel=preload href=https://unpkg.com/@fortawesome/fontawesome-free@6.7.1/css/all.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://unpkg.com/@fortawesome/fontawesome-free@6.7.1/css/all.min.css></noscript><link rel=preload href=https://unpkg.com/animate.css@4.1.1/animate.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://unpkg.com/animate.css@4.1.1/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"推理引擎请求调度优化","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/yitaonote.com\/2025\/8cb0fe8\/"},"genre":"posts","wordcount":3461,"url":"https:\/\/yitaonote.com\/2025\/8cb0fe8\/","datePublished":"2025-08-24T11:36:09+08:00","dateModified":"2025-08-24T11:36:09+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"yitao"},"description":""}</script><script src=/js/head/color-scheme.min.js></script></head><body data-header-desktop=sticky data-header-mobile=auto><div class=wrapper data-page-style=normal><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper data-github-corner=right><div class=header-title><a href=/ title="yitao's Blog"><img class=logo src='https://avatars.githubusercontent.com/u/75578057?s=400&u=523ba40a796b5dc3cdd41fae4a1f038537d2dc67&v=4' alt="yitao's Blog" height=32 width=32><span class=header-title-text>yitao's Blog</span></a><span class=header-subtitle></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 文章</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/collection/><i class="fa-solid fa-bookmark fa-fw fa-sm" aria-hidden=true></i> 集子</a></li><li class=menu-item><a class=menu-link href=/about/><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden=true></i> 关于</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id=search-desktop><input type=text placeholder=搜索文章标题或内容…… id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="yitao's Blog"><img class=logo src='https://avatars.githubusercontent.com/u/75578057?s=400&u=523ba40a796b5dc3cdd41fae4a1f038537d2dc67&v=4' alt="yitao's Blog" height=26 width=26><span class=header-title-text>yitao's Blog</span></a><span class=header-subtitle></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容…… id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></li><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 文章</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/collection/><i class="fa-solid fa-bookmark fa-fw fa-sm" aria-hidden=true></i> 集子</a></li><li class=menu-item><a class=menu-link href=/about/><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden=true></i> 关于</a></li><li class="menu-item menu-system"><span class="menu-system-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></span></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=container><aside class="aside-collection animate__animated animate__fadeIn animate__faster" aria-label=合集></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>推理引擎请求调度优化</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><span class=author><i class="fa-solid fa-user-circle" aria-hidden=true></i>
yitao</span></span><span class=post-included-in>&nbsp;收录于 <a href=/categories/%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/ class=post-category title="分类 - 推理优化"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> 推理优化</a></span></div><div class=post-meta-line><span title="发布于 2025-08-24 11:36:09"><i class="fa-solid fa-calendar-days fa-fw me-1" aria-hidden=true></i><time datetime=2025-08-24>2025-08-24</time></span>&nbsp;<span title="3461 字"><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden=true></i>约 3500 字</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden=true></i>预计阅读 7 分钟</span>&nbsp;</div></div><div class="details toc" id=toc-static data-kept=false><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fa-solid fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#批处理>批处理</a><ul><li><a href=#静态批处理static-batching>静态批处理（Static Batching）</a></li><li><a href=#动态批处理dynamic-batching>动态批处理（Dynamic Batching）</a></li><li><a href=#连续批处理continuous-batching>连续批处理（Continuous Batching）</a></li></ul></li><li><a href=#pd分离>PD分离</a></li><li><a href=#sgl和vllm区别>SGL和vllm区别</a></li><li><a href=#mnn>MNN</a></li><li><a href=#计算图>计算图</a><ul><li><a href=#什么是计算图>什么是计算图？</a></li><li><a href=#pytorch-计算图的核心特点动态性>PyTorch 计算图的核心特点：动态性</a></li><li><a href=#pytorch-计算图是如何构建的>PyTorch 计算图是如何构建的？</a></li><li><a href=#计算图如何用于反向传播>计算图如何用于反向传播？</a></li></ul></li></ul></nav></div></div><div class=content id=content><h2 id=批处理 class=heading-element><span>批处理</span>
<a href=#%e6%89%b9%e5%a4%84%e7%90%86 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>参考文献：<a href=https://zhuanlan.zhihu.com/p/1941421923872514352 target=_blank rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/1941421923872514352</a></p></blockquote><h3 id=静态批处理static-batching class=heading-element><span>静态批处理（Static Batching）</span>
<a href=#%e9%9d%99%e6%80%81%e6%89%b9%e5%a4%84%e7%90%86static-batching class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>请求被放入批处理队列中，当批处理队列满了之后再运行。</p><p>静态批处理是批处理请求最简单的实现。但它会大幅增加延迟，从而限制其使用场景。</p><p>如果说单独运行每个请求就像每个人开自己的车，那么批处理就像一辆公交车。如果公交车采用静态批处理，司机会等待车内乘客满载，然后开往目的地。这确保了公交车每次行驶时都满载。同样，用于模型推理的静态批处理会等到收到一定数量的请求后，再运行单个批处理来同时处理这些请求。</p><p>当对于某个业务流程来说延迟不是问题时，例如每天处理大量文档，静态批处理是最合适的。静态批处理会增加在系统其他位置协调请求的复杂性。使用静态批处理需要一个管理良好的请求队列来为模型提供数据，并且需要一个以大块形式接收模型输出的方法。</p><h3 id=动态批处理dynamic-batching class=heading-element><span>动态批处理（Dynamic Batching）</span>
<a href=#%e5%8a%a8%e6%80%81%e6%89%b9%e5%a4%84%e7%90%86dynamic-batching class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>请求在收到时被分批放置到队列中，在队列满了或自第一个请求以来经过足够的时间后进行批处理。</p><p>静态批处理非常适合日常作业或后台处理。但对于延迟敏感（这里主要是和用户的交互相关业务场景）的生产部署（例如：根据用户输入生成图像），静态批处理并不适用。</p><p>回到我们之前关于公交车的比喻，想象一下，在车流量不大的日子里，你是第一个上车的人。如果你必须等到车上坐满才能出发，那你得等很长时间。但如果司机在第一个乘客上车时启动一个计时器，并在车上坐满或计时器用完（以先到者为准）时出发，那会怎么样呢？这样，你最多只需要等几分钟。</p><p>动态批处理的工作方式相同。您可以使用以下命令设置动态批处理：</p><ol><li>预设的最大批量大小，您希望在每次进行批处理之前达到该大小。</li><li>在运行部分批处理之前接收第一个请求后等待的窗口。</li></ol><p>假设你设置的模型服务器的批处理大小为 16 个请求，窗口为 100 毫秒。当服务器收到第一个请求时，它将：</p><ol><li>在 100 毫秒内接收 15 个以上请求并立即运行完整批次，或者</li><li>接收少于 15 个请求，并在 100 毫秒后运行部分批处理。</li></ol><p>动态批处理非常适合 Stable Diffusion XL 等模型的实时流量，因为每个推理请求所需的时间大致相同。具体部署的正确设置取决于流量模式和延迟要求，但动态批处理可为您提供多种选项的灵活性。</p><p><img loading=lazy src=https://cdn.ipfsscan.io/weibo/large/005wRZF3ly1i4orz4rccug30g00a04ew.gif alt=image></p><h3 id=连续批处理continuous-batching class=heading-element><span>连续批处理（Continuous Batching）</span>
<a href=#%e8%bf%9e%e7%bb%ad%e6%89%b9%e5%a4%84%e7%90%86continuous-batching class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><blockquote><p>来源于 Orca OSDI'22</p></blockquote><p>请求按令牌逐个进行处理，当旧请求完成并释放 GPU 上的空间时，新请求就会得到处理。</p><p>虽然动态批处理非常适合图像生成等场景，其中每个输出大约需要相同的时间来创建，但我们可以通过连续批处理为 LLM 做得更好。</p><p>LLM 会创建一系列 token 作为输出。这些输出序列的长度会有所不同——模型可以回答一个简单的问题，也可以通过逐步推理进行详细的分析。如果使用动态批处理方法，则每批请求都需要等待最长的输出完成后才能开始下一批请求。这会导致 GPU 资源闲置。</p><p>连续批处理在令牌级别而非请求级别进行。LLM 推理的瓶颈在于模型权重的加载。因此，对于连续批处理，模型服务器会按顺序加载模型的每一层，并将其应用于每个请求的下一个令牌。在连续批处理中，相同的模型权重可用于生成一个响应的第 5 个令牌和另一个响应的第 85 个令牌。</p><p>在公交车的例子中，连续批处理类似于现实世界中公交线路的运作方式。当司机沿着路线行驶时，乘客的乘坐时间会有所不同。当一位乘客到达目的地时，就会为另一位乘客腾出座位。</p><p>通过消除等待每个批次的最长响应完成的空闲时间，连续批处理比动态批处理提高了 GPU 的利用率。</p><p><img loading=lazy src=https://cdn.ipfsscan.io/weibo/large/005wRZF3ly1i4orzdt1xlg30hs0b41l3.gif alt=image></p><h2 id=pd分离 class=heading-element><span>PD分离</span>
<a href=#pd%e5%88%86%e7%a6%bb class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>参考文献：<a href=https://zhuanlan.zhihu.com/p/19796399275 target=_blank rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/19796399275</a></p></blockquote><h2 id=sgl和vllm区别 class=heading-element><span>SGL和vllm区别</span>
<a href=#sgl%e5%92%8cvllm%e5%8c%ba%e5%88%ab class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>参考：<a href=https://www.zhihu.com/question/666943660/answer/1940915117643530378 target=_blank rel="external nofollow noopener noreferrer">https://www.zhihu.com/question/666943660/answer/1940915117643530378</a></p></blockquote><h2 id=mnn class=heading-element><span>MNN</span>
<a href=#mnn class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>MNN 是一个为移动端和嵌入式设备设计的轻量级深度学习推理引擎。它的核心目标是在资源有限的硬件上，如手机、物联网设备和智能家居，高效地运行神经网络模型。</p><ul><li><p>设计理念： 追求极致的轻量化和高性能。它通过各种优化技术，如量化、模型压缩、算子融合和硬件加速，来减少模型大小、降低内存占用和提升计算速度。</p></li><li><p>支持模型： 主要用于视觉、语音和传统机器学习任务，例如图像分类、目标检测、人脸识别、风格迁移和语音识别。</p></li><li><p>优化重点：</p></li><li><p>异构计算： 充分利用 CPU、GPU 和 DSP 等不同硬件的特性。</p></li><li><p>内存优化： 采用内存池等技术，减少内存分配和碎片化。</p></li><li><p>量化技术： 支持 FP32、FP16、Int8 等多种数据类型，以适应不同硬件平台并提升性能。</p></li></ul><p>LLM 推理引擎 专门为大型语言模型设计，如 Llama、GPT 和 Mistral 等。这些模型通常拥有数百亿甚至上万亿的参数，对计算和内存资源的需求极高。</p><ul><li><p>设计理念： 旨在解决 LLM 推理中的独特挑战，包括巨大的模型尺寸、高昂的计算量和 KV 缓存（Key-Value Cache）的内存开销。</p></li><li><p>支持模型： 专注于处理基于 Transformer 架构的超大规模语言模型。</p></li><li><p>优化重点：</p></li><li><p>并行计算： 利用多 GPU 和分布式计算来加载和运行庞大的模型。</p></li><li><p>KV 缓存管理： 优化注意力机制中的 KV 缓存，以减少内存占用并提升推理速度。</p></li><li><p>FlashAttention 等高效算法： 采用专门为 Transformer 设计的优化算法，以减少显存访问并提升计算效率。</p></li><li><p>量化和剪枝： 虽然 MNN 也使用这些技术，但 LLM 推理引擎中的量化通常更复杂，需要确保量化后模型的性能损失最小。</p></li><li><p>动态批处理： 动态地调整批处理大小，以最大化 GPU 利用率。</p></li></ul><h2 id=计算图 class=heading-element><span>计算图</span>
<a href=#%e8%ae%a1%e7%ae%97%e5%9b%be class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><h3 id=什么是计算图 class=heading-element><span>什么是计算图？</span>
<a href=#%e4%bb%80%e4%b9%88%e6%98%af%e8%ae%a1%e7%ae%97%e5%9b%be class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>首先，计算图是一种有向无环图（DAG, Directed Acyclic Graph），它用来描述运算操作之间的关系。在图中：</p><p>节点（Nodes） 代表数据（张量 Tensor）或者操作（Operations）。</p><p>边（Edges） 代表数据流向，表示数据从一个操作传递到另一个操作。</p><p>举一个最简单的例子，假设我们有这样一个数学表达式： y = (a + b) * c</p><p>这个表达式可以用如下的计算图来表示：</p><h3 id=pytorch-计算图的核心特点动态性 class=heading-element><span>PyTorch 计算图的核心特点：动态性</span>
<a href=#pytorch-%e8%ae%a1%e7%ae%97%e5%9b%be%e7%9a%84%e6%a0%b8%e5%bf%83%e7%89%b9%e7%82%b9%e5%8a%a8%e6%80%81%e6%80%a7 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>这是 PyTorch 与 TensorFlow 1.x 等早期框架最显著的区别。</p><ul><li><p>静态图 (Static Graph - 如 TensorFlow 1.x):</p><ul><li><p>定义与运行分离 (Define-and-Run)。 你需要先完整地定义好整个计算图的结构，然后才能向这个固定的图中输入数据并执行它。</p></li><li><p>优点： 可以在运行前对整个图进行优化，例如分配显存、融合算子，因此潜在的性能可能更高。</p></li><li><p>缺点： 不够灵活。对于需要根据输入数据动态改变计算流程的模型（如循环神经网络 RNN 中处理不同长度的序列），定义起来非常麻烦和不直观。</p></li></ul></li><li><p>动态图 (Dynamic Graph - PyTorch):</p><ul><li><p>定义与运行合一 (Define-by-Run)。 计算图是在代码运行时动态生成的。每当你执行一个操作，一个新的节点和相应的边就被添加到图中。</p></li><li><p>优点：</p></li><li><p>直观灵活： 代码所见即所得，你可以像写普通 Python 程序一样使用 if/else、for 循环等控制流语句，计算图会根据你的执行路径自然地构建出来。这使得调试非常方便。</p></li><li><p>易于处理动态输入： 对于 RNN 等模型极为友好。</p></li><li><p>缺点： 理论上，由于图是动态生成的，难以进行全局优化，可能会有一些性能开销。但随着 PyTorch 的发展（如 torch.jit.script 和 TorchDynamo），这个差距正在被不断缩小。</p></li></ul></li></ul><h3 id=pytorch-计算图是如何构建的 class=heading-element><span>PyTorch 计算图是如何构建的？</span>
<a href=#pytorch-%e8%ae%a1%e7%ae%97%e5%9b%be%e6%98%af%e5%a6%82%e4%bd%95%e6%9e%84%e5%bb%ba%e7%9a%84 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>PyTorch 的计算图是在前向传播（Forward Pass） 过程中，由 autograd 系统自动构建的。这个图记录了所有张量以及对它们进行的操作历史。</p><p>我们来看关键的几个组件：</p><ul><li><p>torch.Tensor: 这是图中的核心数据结构。一个张量有几个重要属性：</p><ul><li><p>data: 存储张量的实际数据。</p></li><li><p>requires_grad: 一个布尔值。如果为 True，表示该张量需要计算梯度。autograd 系统会从这个张量开始追踪所有操作。通常，模型的权重参数该值为 True，而输入数据默认为 False。</p></li><li><p>grad: 存储计算出的梯度值。初始时为 None。</p></li><li><p>grad_fn: 这是构建计算图的关键！ 它引用了一个 Function 对象，该对象记录了创建这个张量的操作。如果一个张量是用户直接创建的（叶子节点），那么它的 grad_fn 为 None。</p></li></ul></li></ul><h3 id=计算图如何用于反向传播 class=heading-element><span>计算图如何用于反向传播？</span>
<a href=#%e8%ae%a1%e7%ae%97%e5%9b%be%e5%a6%82%e4%bd%95%e7%94%a8%e4%ba%8e%e5%8f%8d%e5%90%91%e4%bc%a0%e6%92%ad class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>计算图最重要的作用就是为了计算梯度。当你对某个张量（通常是最终的损失 <code>loss</code>）调用 <code>.backward()</code> 方法时，<code>autograd</code> 引擎就会启动。</p><p>过程如下：</p><ol><li><p>启动： 从调用 .backward() 的张量（例如 y）开始，传入一个初始梯度（对于标量，默认为 1.0）。</p></li><li><p>反向遍历： autograd 引擎沿着计算图，从根节点 y 向叶子节点 a, b, c 反向传播。</p></li><li><p>链式法则： 在每个节点处，autograd 会使用该节点的 grad_fn 来计算输入张量相对于当前节点的梯度。这本质上就是应用微积分中的链式法则。</p><ul><li><p>例如，在 y 节点，autograd 计算 y 对 d 和 c 的偏导数。</p></li><li><p>然后传播到 d 节点，autograd 计算 d 对 a 和 b 的偏导数。</p></li></ul></li><li><p>梯度累积： 计算出的梯度会被**累积（accumulate）**到各个叶子节点的 .grad 属性中。这就是为什么在每个训练迭代开始时，我们通常需要调用 optimizer.zero_grad()，否则梯度会一直叠加。</p></li></ol></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="更新于 2025-08-24 11:36:09">更新于 2025-08-24&nbsp;</span></div></div><div class=post-info-line><div class=post-info-md><span><a href=/2025/8cb0fe8/index.md title=阅读原始文档 class=link-to-markdown>阅读原始文档</a></span></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 Pocket" data-sharer=pocket data-url=https://yitaonote.com/2025/8cb0fe8/><i class="fa-brands fa-get-pocket fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=https://yitaonote.com/2025/8cb0fe8/ data-title=推理引擎请求调度优化><i class="fa-brands fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/2025/34980c2/ class=post-nav-item rel=prev title=GPU及CUDA基本概念><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>GPU及CUDA基本概念</a><a href=/2025/a793bc7/ class=post-nav-item rel=next title=量化>量化<i class="fa-solid fa-angle-right fa-fw" aria-hidden=true></i></a></div></div><div class=post-reward><div class=comment></div><input type=checkbox class=reward-input name=reward id=fi-reward hidden>
<label class=reward-button for=fi-reward><i class="fa-solid fa-qrcode fa-fw" aria-hidden=true></i>赞赏</label><div class=reward-ways data-mode=static><div><img src=https://cdn.ipfsscan.io/weibo/large/005wRZF3ly1i429ilg93xj30u018zjut.jpg alt="yitao 支付宝"><span>支付宝</span></div><div><img src=https://cdn.ipfsscan.io/weibo/large/005wRZF3ly1i429iozq5hj30n00v8gne.jpg alt="yitao 微信"><span>微信</span></div></div></div><div id=comments><div id=giscus class=comment><script src=https://giscus.app/client.js data-repo=walker-ai/walker-ai.github.io data-repo-id=R_kgDOOM9c8w data-category=Announcements data-category-id=DIC_kwDOOM9c884CoX_P data-mapping=pathname data-strict=0 data-theme=preferred_color_scheme data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-lang=zh-CN data-loading=lazy crossorigin=anonymous async defer></script></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://giscus.app/ rel="external nofollow noopener noreferrer">giscus</a>.</noscript></div></article><aside class=toc id=toc-auto aria-label=目录><h2 class=toc-title>目录&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden=true></i></h2><div class=toc-content id=toc-content-auto></div></aside></main><footer class=footer><div class=footer-container><div class="footer-line powered">由 <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.145.0"><img class=hugo-icon src=/images/hugo.min.svg alt="Hugo logo"> Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/hugo-fixit/FixIt target=_blank rel=external title="FixIt v0.3.17-8212d6fd"><img class=fixit-icon src=/images/fixit.min.svg alt="FixIt logo"> FixIt</a></div><div class="footer-line copyright" itemscope itemtype=http://schema.org/CreativeWork><i class="fa-regular fa-copyright fa-fw" aria-hidden=true></i>
<span itemprop=copyrightYear>2018 - 2025</span><span class=author itemprop=copyrightHolder>
<a href=/></a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label=回到顶部><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class="variant-numeric d-none">0%</span></div><div class="fixed-button view-comments d-none" role=button aria-label=查看评论><i class="fa-solid fa-comment fa-fw" aria-hidden=true></i></div></div><a href=https://github.com/walker-ai/walker-ai.github.io title="View source on GitHub" target=_blank rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true" width="56" height="56"><path d="M0 0 115 115h15l12 27L250 250V0z"/><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentcolor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4l13.9-13.8C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8z" fill="currentcolor" class="octo-body"/></svg></a><div id=mask></div><div class=reading-progress-bar style=left:0;top:0></div><noscript><div class=noscript-warning>该网站在启用 JavaScript 的情况下效果最佳。</div></noscript></div><link rel=preload href=https://unpkg.com/katex@0.16.10/dist/katex.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://unpkg.com/katex@0.16.10/dist/katex.min.css></noscript><link rel=stylesheet href=https://unpkg.com/pace-js@1.2.4/themes/blue/pace-theme-minimal.css><script src=https://unpkg.com/autocomplete.js@0.38.1/dist/autocomplete.min.js defer></script><script src=https://unpkg.com/fuse.js@6.6.2/dist/fuse.min.js defer></script><script src=https://unpkg.com/twemoji@14.0.2/dist/twemoji.min.js defer></script><script src=https://unpkg.com/sharer.js@0.5.1/sharer.min.js async defer></script><script src=https://unpkg.com/katex@0.16.10/dist/katex.min.js defer></script><script src=https://unpkg.com/katex@0.16.10/dist/contrib/auto-render.min.js defer></script><script src=https://unpkg.com/katex@0.16.10/dist/contrib/mhchem.min.js defer></script><script src=https://unpkg.com/pangu@4.0.7/dist/browser/pangu.min.js defer></script><script src=https://unpkg.com/pace-js@1.2.4/pace.min.js async defer></script><script>window.config={code:{copyTitle:"复制到剪贴板",maxShownLines:100},comment:{enable:!0,expired:!1,giscus:{darkTheme:"dark",lightTheme:"light",origin:"https://giscus.app"}},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},pangu:{enable:!0,selector:"article"},search:{distance:100,findAllMatches:!1,fuseIndexURL:"/search.json",highlightTag:"em",ignoreFieldNorm:!1,ignoreLocation:!1,isCaseSensitive:!1,location:0,maxResultLength:10,minMatchCharLength:2,noResultsFound:"没有找到结果",snippetLength:30,threshold:.3,type:"fuse",useExtendedSearch:!1},twemoji:!0,version:"v0.3.17-8212d6fd"}</script><script src=/js/theme.min.js defer></script></body></html>