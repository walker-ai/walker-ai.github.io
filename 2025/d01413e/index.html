<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>DeepSeek相关优化技术 - yitao's Blog</title><meta name=author content="yitao">
<meta name=description content="yitao的学习笔记"><meta name=keywords content='Blog,Blockchain,Book,Movie,Life,Journey'><meta itemprop=name content="DeepSeek相关优化技术"><meta itemprop=description content="yitao的学习笔记"><meta itemprop=datePublished content="2025-08-14T00:15:18+08:00"><meta itemprop=dateModified content="2025-08-14T00:15:18+08:00"><meta itemprop=wordCount content="5635"><meta itemprop=image content="https://yitaonote.com/logo.png"><meta itemprop=keywords content="推理优化"><meta property="og:url" content="https://yitaonote.com/2025/d01413e/"><meta property="og:site_name" content="yitao's Blog"><meta property="og:title" content="DeepSeek相关优化技术"><meta property="og:description" content="yitao的学习笔记"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-08-14T00:15:18+08:00"><meta property="article:modified_time" content="2025-08-14T00:15:18+08:00"><meta property="og:image" content="https://yitaonote.com/logo.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://yitaonote.com/logo.png"><meta name=twitter:title content="DeepSeek相关优化技术"><meta name=twitter:description content="yitao的学习笔记"><meta name=application-name content="yitao's Blog"><meta name=apple-mobile-web-app-title content="yitao's Blog"><meta name=theme-color data-light=#f8f8f8 data-dark=#252627 content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=canonical type=text/html href=https://yitaonote.com/2025/d01413e/ title="DeepSeek相关优化技术 - yitao's Blog"><link rel=prev type=text/html href=https://yitaonote.com/2025/a793bc7/ title=量化><link rel=next type=text/html href=https://yitaonote.com/2025/39b641b/ title=softmax与Flash-attention><link rel=alternate type=text/markdown href=https://yitaonote.com/2025/d01413e/index.md title="DeepSeek相关优化技术 - yitao's Blog"><link rel=stylesheet href=/css/style.min.css><link rel=preload href=https://unpkg.com/@fortawesome/fontawesome-free@6.7.1/css/all.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://unpkg.com/@fortawesome/fontawesome-free@6.7.1/css/all.min.css></noscript><link rel=preload href=https://unpkg.com/animate.css@4.1.1/animate.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://unpkg.com/animate.css@4.1.1/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"DeepSeek相关优化技术","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/yitaonote.com\/2025\/d01413e\/"},"genre":"posts","wordcount":5635,"url":"https:\/\/yitaonote.com\/2025\/d01413e\/","datePublished":"2025-08-14T00:15:18+08:00","dateModified":"2025-08-14T00:15:18+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"yitao"},"description":""}</script><script src=/js/head/color-scheme.min.js></script></head><body data-header-desktop=sticky data-header-mobile=auto><div class=wrapper data-page-style=normal><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper data-github-corner=right><div class=header-title><a href=/ title="yitao's Blog"><img class=logo src='https://avatars.githubusercontent.com/u/75578057?s=400&u=523ba40a796b5dc3cdd41fae4a1f038537d2dc67&v=4' alt="yitao's Blog" height=32 width=32><span class=header-title-text>yitao's Blog</span></a><span class=header-subtitle></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 文章</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/collection/><i class="fa-solid fa-bookmark fa-fw fa-sm" aria-hidden=true></i> 集子</a></li><li class=menu-item><a class=menu-link href=/about/><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden=true></i> 关于</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id=search-desktop><input type=text placeholder=搜索文章标题或内容…… id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="yitao's Blog"><img class=logo src='https://avatars.githubusercontent.com/u/75578057?s=400&u=523ba40a796b5dc3cdd41fae4a1f038537d2dc67&v=4' alt="yitao's Blog" height=26 width=26><span class=header-title-text>yitao's Blog</span></a><span class=header-subtitle></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容…… id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></li><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 文章</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/collection/><i class="fa-solid fa-bookmark fa-fw fa-sm" aria-hidden=true></i> 集子</a></li><li class=menu-item><a class=menu-link href=/about/><i class="fa-solid fa-info-circle fa-fw fa-sm" aria-hidden=true></i> 关于</a></li><li class="menu-item menu-system"><span class="menu-system-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></span></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=container><aside class="aside-collection animate__animated animate__fadeIn animate__faster" aria-label=合集></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>DeepSeek相关优化技术</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><span class=author><i class="fa-solid fa-user-circle" aria-hidden=true></i>
yitao</span></span><span class=post-included-in>&nbsp;收录于 <a href=/categories/%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/ class=post-category title="分类 - 推理优化"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> 推理优化</a></span></div><div class=post-meta-line><span title="发布于 2025-08-14 00:15:18"><i class="fa-solid fa-calendar-days fa-fw me-1" aria-hidden=true></i><time datetime=2025-08-14>2025-08-14</time></span>&nbsp;<span title="5635 字"><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden=true></i>约 5700 字</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden=true></i>预计阅读 12 分钟</span>&nbsp;</div></div><div class="details toc" id=toc-static data-kept=false><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fa-solid fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#mla>MLA</a><ul><li><a href=#朴素实现>朴素实现</a></li><li><a href=#矩阵吸收>矩阵吸收</a></li><li><a href=#朴素实现包含rope>朴素实现（包含rope）</a></li><li><a href=#矩阵吸收包含rope>矩阵吸收（包含rope）</a></li></ul></li><li><a href=#moe>MoE</a></li><li><a href=#mtp>MTP</a></li><li><a href=#deepseek开源周>DeepSeek开源周</a><ul><li><a href=#flashmla>FlashMLA</a></li><li><a href=#deepep>DeepEP</a></li><li><a href=#deepgemm>DeepGEMM</a></li><li><a href=#eplb>EPLB</a><ul><li><a href=#背景动机>背景动机</a></li><li><a href=#eplb核心函数>EPLB核心函数</a></li><li><a href=#核心api>核心API</a></li></ul></li></ul></li></ul></nav></div></div><div class=content id=content><h2 id=mla class=heading-element><span>MLA</span>
<a href=#mla class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p><a href="https://www.bilibili.com/video/BV1jDLBzoE1e/?spm_id_from=333.337.search-card.all.click&amp;vd_source=d436f8a78656c9132eae4a84f939d219" target=_blank rel="external nofollow noopener noreferrer">参考图解视频</a></p></blockquote><h3 id=朴素实现 class=heading-element><span>朴素实现</span>
<a href=#%e6%9c%b4%e7%b4%a0%e5%ae%9e%e7%8e%b0 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p><img loading=lazy src=https://cdn.ipfsscan.io/weibo/large/005wRZF3ly1i4kr9o3jfcj31c40u0wjj.jpg alt=image></p><h3 id=矩阵吸收 class=heading-element><span>矩阵吸收</span>
<a href=#%e7%9f%a9%e9%98%b5%e5%90%b8%e6%94%b6 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p><img loading=lazy src=https://cdn.ipfsscan.io/weibo/large/005wRZF3ly1i4kr9jozmfj320o0qhn2j.jpg alt=image></p><div class="details admonition tip open disabled"><div class="details-summary admonition-title"><i class="icon fa-fw fa-regular fa-lightbulb" aria-hidden=true></i>上面图解版本不包括<strong>旋转位置编码</strong>，但我认为用来理解MLA基本原理还是非常好的</div><div class=details-content><div class=admonition-content></div></div></div><h3 id=朴素实现包含rope class=heading-element><span>朴素实现（包含rope）</span>
<a href=#%e6%9c%b4%e7%b4%a0%e5%ae%9e%e7%8e%b0%e5%8c%85%e5%90%abrope class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><blockquote><p>参考文献：<a href=https://zhuanlan.zhihu.com/p/1901704483446187870 target=_blank rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/1901704483446187870</a></p></blockquote><p><img loading=lazy src=https://cdn.ipfsscan.io/weibo/large/005wRZF3ly1i4kr76q5blj31400iywg9.jpg alt=image></p><div class="details admonition tip open disabled"><div class="details-summary admonition-title"><i class="icon fa-fw fa-regular fa-lightbulb" aria-hidden=true></i>$t$ 代表 t-th token</div><div class=details-content><div class=admonition-content></div></div></div><p>首先输入 $h_t$ 经过 $W_{DQ}$ 得到 $c_t^Q$ 再分别经过 $W^{QR}$, $W^{UQ}$ 得到用于 rope计算的 $q_t^R$ 和 nope 的 $q_t^C$：</p>$$
\begin{aligned}
h_{t}W_{DQ} &= c_{t}^{Q} \\
c_{t}^{Q}W^{QR} &= q_{t}^{R} \\
c_{t}^{Q}W^{UQ} &= q_{t}^{C} \\
\end{aligned}
$$<p>其次来看 KV 部分，输入 $h_t$ 经过 $W_{DKV}$ 得到 $c_t^{KV}$，得到联合低秩压缩的 KV，$c_t^{KV}$ 与历史的 c cache拼接后，得到完整的 $c^{KV}$，
再分别经过 $W_{UK}$，$W_{UV}$ 进行升维，得到 $k^C$，$v^C$：</p>$$
\begin{aligned}
XW_{DKV} &= c_t^{KV} \\
c^{KV}W_{UK} &= k^C\\
c^{KV}W_{UV} &= v^C \\
\end{aligned}
$$<p>再回到输入部分，现在来计算 qk 的rope部分，输入 $h_t$ 经过 $W_{KR}$ 得到 $k_t^R$，同样与历史的 $k_pe$ cache拼接后，得到完整的 $k^R$，然后与 $q_t^R$ 进行 rope计算：</p>$$
\begin{aligned}
h_tW^{KR} &= k_t^R \\
q_t^R(k^R)^T &= \text{attn}^R
\end{aligned}
$$<p>得到 $\text{attn}^R$ 后，我们再回到之前的计算过程，我们之前计算得到了 $q_t^C$ 和完整的 $k^C$，因此可以计算出 attn 的nope部分：</p>$$
\begin{aligned}
q_t^C(k^C)^T &= \text{attn}^C
\end{aligned}
$$<p>故：</p>$$
Softmax(\dfrac{QK^T}{\sqrt{d}}) = Softmax(\dfrac{\text{attn}^C + \text{attn}^R}{\sqrt{d}})
$$<p>然后再与v进行相乘得到最终的注意力输出：</p>$$
\begin{aligned}
PV &= Softmax(\dfrac{\text{attn}^C + \text{attn}^R}{\sqrt{d}})v^C \\
O &=  Softmax(\dfrac{\text{attn}^C + \text{attn}^R}{\sqrt{d}})v^C W_o
\end{aligned}
$$<h3 id=矩阵吸收包含rope class=heading-element><span>矩阵吸收（包含rope）</span>
<a href=#%e7%9f%a9%e9%98%b5%e5%90%b8%e6%94%b6%e5%8c%85%e5%90%abrope class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p><img loading=lazy src=https://cdn.ipfsscan.io/weibo/large/005wRZF3ly1i4krhbv6mcj31400iymyx.jpg alt=image></p><p>主要是将 $c_{t}^{Q}W^{UQ} = q_{t}^{C}$ 和 $c^{KV}W_{UK} = k^C$ 这两步中的 $W^{UQ}$ 和 $W^{UK}$ 吸收到了 $W^{UQK}$，使得
$\text{attn}^C$ 的计算可以直接由 $q_t^C(c^{KV})^T = \text{attn}^C$ 得到，而不需要先对低秩联合压缩的 $c^{KV}$ 先做升维得到 $k^C$，即解压操作。</p><p>另外是将 $c^{KV}W^{UV} = v^C$ 和 $O = Softmax(\dfrac{\text{attn}^C + \text{attn}^R}{\sqrt{d}})v^C W_o$ 这两步中的 $W^{UV}$ 和 $W_o$ 吸收到了 $W^{UVO}$，使得注意力输出的 $O$ 的计算可以直接由 $Softmax(\dfrac{\text{attn}^C + \text{attn}^R}{\sqrt{d}})W^{UVO}$ 得到，而不需要先对低秩联合压缩的 $c^{KV}$ 先做升维得到 $v^C$，即解压操作。</p><p><strong>总结：</strong>
这样做可以直接在潜在空间（即压缩后的维度）中进行注意力计算，而不需要先解压 KV-Cache。并且能够减少计算量：通过将两个矩阵相乘的操作合并成一个，减少了所需的计算步骤，从而提高了推理速度。简单来说，矩阵吸收就像是把一个两步走的任务（先解压，再计算）变成了一步走的任务（直接用“吸收”后的矩阵进行计算），从而实现了内存和计算效率的双重优化。</p><h2 id=moe class=heading-element><span>MoE</span>
<a href=#moe class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Expert</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>net</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>GELU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>net</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>MoE</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>,</span> <span class=n>num_experts</span><span class=p>,</span> <span class=n>top_k</span><span class=p>,</span> <span class=n>expert_capacity</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>num_experts</span> <span class=o>=</span> <span class=n>num_experts</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>top_k</span> <span class=o>=</span> <span class=n>top_k</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>expert_capacity</span> <span class=o>=</span> <span class=n>expert_capacity</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 路由网络</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>gate</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>num_experts</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 专家集合</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>experts</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=p>[</span><span class=n>Expert</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_experts</span><span class=p>)])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_size</span><span class=p>,</span> <span class=n>input_dim</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>        <span class=n>device</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>device</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 路由计算</span>
</span></span><span class=line><span class=cl>        <span class=n>logits</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>gate</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>probs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;probs: &#34;</span><span class=p>,</span> <span class=n>probs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>topk_probs</span><span class=p>,</span> <span class=n>topk_indices</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>topk</span><span class=p>(</span><span class=n>probs</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>top_k</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;topk_probs: &#34;</span><span class=p>,</span> <span class=n>topk_probs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;topk_indices: &#34;</span><span class=p>,</span> <span class=n>topk_indices</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 辅助损失计算</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>training</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 重要性损失（专家利用率均衡）</span>
</span></span><span class=line><span class=cl>            <span class=n>importance</span> <span class=o>=</span> <span class=n>probs</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>importance_loss</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>importance</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>num_experts</span> <span class=o>**</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 负载均衡损失（样本分配均衡）</span>
</span></span><span class=line><span class=cl>            <span class=n>mask</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros_like</span><span class=p>(</span><span class=n>probs</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>bool</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>mask</span><span class=o>.</span><span class=n>scatter_</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>topk_indices</span><span class=p>,</span> <span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>routing_probs</span> <span class=o>=</span> <span class=n>probs</span> <span class=o>*</span> <span class=n>mask</span>
</span></span><span class=line><span class=cl>            <span class=n>expert_usage</span> <span class=o>=</span> <span class=n>mask</span><span class=o>.</span><span class=n>float</span><span class=p>()</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>routing_weights</span> <span class=o>=</span> <span class=n>routing_probs</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>load_balance_loss</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>num_experts</span> <span class=o>*</span> <span class=p>(</span><span class=n>expert_usage</span> <span class=o>*</span> <span class=n>routing_weights</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>aux_loss</span> <span class=o>=</span> <span class=n>importance_loss</span> <span class=o>+</span> <span class=n>load_balance_loss</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>aux_loss</span> <span class=o>=</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 专家分配逻辑</span>
</span></span><span class=line><span class=cl>        <span class=n>flat_indices</span> <span class=o>=</span> <span class=n>topk_indices</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>flat_probs</span> <span class=o>=</span> <span class=n>topk_probs</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>sample_indices</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)[:,</span> <span class=kc>None</span><span class=p>]</span>\
</span></span><span class=line><span class=cl>                            <span class=o>.</span><span class=n>expand</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>top_k</span><span class=p>)</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;sample_indices: &#34;</span><span class=p>,</span> <span class=n>sample_indices</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 初始化输出</span>
</span></span><span class=line><span class=cl>        <span class=n>outputs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>experts</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>net</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>out_features</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                            <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 处理每个专家</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>expert_idx</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>num_experts</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;expert_idx: &#34;</span><span class=p>,</span> <span class=n>expert_idx</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1># 获取分配给当前专家的样本</span>
</span></span><span class=line><span class=cl>            <span class=n>expert_mask</span> <span class=o>=</span> <span class=n>flat_indices</span> <span class=o>==</span> <span class=n>expert_idx</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;expert_mask: &#34;</span><span class=p>,</span> <span class=n>expert_mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>expert_samples</span> <span class=o>=</span> <span class=n>sample_indices</span><span class=p>[</span><span class=n>expert_mask</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;expert_samples: &#34;</span><span class=p>,</span> <span class=n>expert_samples</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>expert_weights</span> <span class=o>=</span> <span class=n>flat_probs</span><span class=p>[</span><span class=n>expert_mask</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;expert_weights: &#34;</span><span class=p>,</span> <span class=n>expert_weights</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 容量控制</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>expert_samples</span><span class=p>)</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>expert_capacity</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>expert_samples</span> <span class=o>=</span> <span class=n>expert_samples</span><span class=p>[:</span><span class=bp>self</span><span class=o>.</span><span class=n>expert_capacity</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                <span class=n>expert_weights</span> <span class=o>=</span> <span class=n>expert_weights</span><span class=p>[:</span><span class=bp>self</span><span class=o>.</span><span class=n>expert_capacity</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>expert_samples</span><span class=p>)</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>continue</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 处理专家计算</span>
</span></span><span class=line><span class=cl>            <span class=n>expert_input</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>expert_samples</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;expert_input: &#34;</span><span class=p>,</span> <span class=n>expert_input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>expert_output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>experts</span><span class=p>[</span><span class=n>expert_idx</span><span class=p>](</span><span class=n>expert_input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>weighted_output</span> <span class=o>=</span> <span class=n>expert_output</span> <span class=o>*</span> <span class=n>expert_weights</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 累加输出</span>
</span></span><span class=line><span class=cl>            <span class=n>outputs</span><span class=o>.</span><span class=n>index_add_</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>expert_samples</span><span class=p>,</span> <span class=n>weighted_output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>outputs</span><span class=p>,</span> <span class=n>aux_loss</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 测试示例</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>input_dim</span> <span class=o>=</span> <span class=mi>5</span>
</span></span><span class=line><span class=cl>    <span class=n>output_dim</span> <span class=o>=</span> <span class=mi>10</span>
</span></span><span class=line><span class=cl>    <span class=n>num_experts</span> <span class=o>=</span> <span class=mi>8</span>
</span></span><span class=line><span class=cl>    <span class=n>top_k</span> <span class=o>=</span> <span class=mi>3</span>
</span></span><span class=line><span class=cl>    <span class=n>expert_capacity</span> <span class=o>=</span> <span class=mi>32</span>
</span></span><span class=line><span class=cl>    <span class=n>hidden_dim</span> <span class=o>=</span> <span class=mi>512</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span> <span class=o>=</span> <span class=mi>10</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># add</span>
</span></span><span class=line><span class=cl>    <span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&#34;npu:4&#34;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>npu</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>&#34;cpu&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>moe</span> <span class=o>=</span> <span class=n>MoE</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=n>num_experts</span><span class=p>,</span> <span class=n>top_k</span><span class=p>,</span> <span class=n>expert_capacity</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>output_dim</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>moe</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>output</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>moe</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Eval output shape: </span><span class=si>{</span><span class=n>output</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span> <span class=c1># torch.Size([64, 256])</span></span></span></code></pre></td></tr></table></div></div><p>gate 就是一个线性层，形状为 <code>(hidden_state, n_experts)</code></p><p>输入 x (num_tokens, hidden_state) 经过 gate 得到 router_logits (num_tokens, n_experts)</p><p>然后会经过 topk 来将每个token对应的topk个激活专家选出来，这里可以用python代码简单介绍这一过程：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>logits</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>gate</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>probs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div><p>假设这里的 <code>num_tokens=10, num_experts=8</code>，故 probs 是一个10行8列的矩阵</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>probs</span><span class=p>:</span>  
</span></span><span class=line><span class=cl><span class=n>tensor</span><span class=p>([[</span><span class=mf>0.1710</span><span class=p>,</span> <span class=mf>0.1348</span><span class=p>,</span> <span class=mf>0.0746</span><span class=p>,</span> <span class=mf>0.1714</span><span class=p>,</span> <span class=mf>0.0594</span><span class=p>,</span> <span class=mf>0.2695</span><span class=p>,</span> <span class=mf>0.0251</span><span class=p>,</span> <span class=mf>0.0940</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mf>0.1556</span><span class=p>,</span> <span class=mf>0.0776</span><span class=p>,</span> <span class=mf>0.1658</span><span class=p>,</span> <span class=mf>0.1489</span><span class=p>,</span> <span class=mf>0.1152</span><span class=p>,</span> <span class=mf>0.1679</span><span class=p>,</span> <span class=mf>0.0565</span><span class=p>,</span> <span class=mf>0.1124</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mf>0.1077</span><span class=p>,</span> <span class=mf>0.1154</span><span class=p>,</span> <span class=mf>0.1564</span><span class=p>,</span> <span class=mf>0.1317</span><span class=p>,</span> <span class=mf>0.0630</span><span class=p>,</span> <span class=mf>0.2026</span><span class=p>,</span> <span class=mf>0.0518</span><span class=p>,</span> <span class=mf>0.1715</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mf>0.0681</span><span class=p>,</span> <span class=mf>0.0680</span><span class=p>,</span> <span class=mf>0.1236</span><span class=p>,</span> <span class=mf>0.1030</span><span class=p>,</span> <span class=mf>0.1707</span><span class=p>,</span> <span class=mf>0.2827</span><span class=p>,</span> <span class=mf>0.0627</span><span class=p>,</span> <span class=mf>0.1211</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mf>0.0453</span><span class=p>,</span> <span class=mf>0.0648</span><span class=p>,</span> <span class=mf>0.2313</span><span class=p>,</span> <span class=mf>0.0781</span><span class=p>,</span> <span class=mf>0.1026</span><span class=p>,</span> <span class=mf>0.1304</span><span class=p>,</span> <span class=mf>0.1326</span><span class=p>,</span> <span class=mf>0.2149</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mf>0.1394</span><span class=p>,</span> <span class=mf>0.2278</span><span class=p>,</span> <span class=mf>0.0625</span><span class=p>,</span> <span class=mf>0.1832</span><span class=p>,</span> <span class=mf>0.0395</span><span class=p>,</span> <span class=mf>0.1512</span><span class=p>,</span> <span class=mf>0.0691</span><span class=p>,</span> <span class=mf>0.1274</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mf>0.1096</span><span class=p>,</span> <span class=mf>0.1462</span><span class=p>,</span> <span class=mf>0.1302</span><span class=p>,</span> <span class=mf>0.1397</span><span class=p>,</span> <span class=mf>0.0607</span><span class=p>,</span> <span class=mf>0.1898</span><span class=p>,</span> <span class=mf>0.0639</span><span class=p>,</span> <span class=mf>0.1598</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mf>0.1200</span><span class=p>,</span> <span class=mf>0.1952</span><span class=p>,</span> <span class=mf>0.0970</span><span class=p>,</span> <span class=mf>0.1648</span><span class=p>,</span> <span class=mf>0.0360</span><span class=p>,</span> <span class=mf>0.1072</span><span class=p>,</span> <span class=mf>0.1018</span><span class=p>,</span> <span class=mf>0.1779</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mf>0.0650</span><span class=p>,</span> <span class=mf>0.0501</span><span class=p>,</span> <span class=mf>0.1463</span><span class=p>,</span> <span class=mf>0.1025</span><span class=p>,</span> <span class=mf>0.2219</span><span class=p>,</span> <span class=mf>0.1446</span><span class=p>,</span> <span class=mf>0.1439</span><span class=p>,</span> <span class=mf>0.1257</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mf>0.0641</span><span class=p>,</span> <span class=mf>0.0813</span><span class=p>,</span> <span class=mf>0.0579</span><span class=p>,</span> <span class=mf>0.1348</span><span class=p>,</span> <span class=mf>0.1170</span><span class=p>,</span> <span class=mf>0.0631</span><span class=p>,</span> <span class=mf>0.3554</span><span class=p>,</span> <span class=mf>0.1264</span><span class=p>]],</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></td></tr></table></div></div><p>接着，再用topk算子把每个token的激活专家选出来：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>topk_probs</span><span class=p>,</span> <span class=n>topk_indices</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>topk</span><span class=p>(</span><span class=n>probs</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>top_k</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div><div class="details admonition tip open disabled"><div class="details-summary admonition-title"><i class="icon fa-fw fa-regular fa-lightbulb" aria-hidden=true></i>由此可见 top-k 算子也是非常重要的，实现过程可以看 <a href=https://yitaonote.com/2025/ebaa040/ target=_blank rel="external nofollow noopener noreferrer">CUDA常用算子案例</a></div><div class=details-content><div class=admonition-content></div></div></div><p><code>topk_probs</code>和<code>topk_indices</code> 的打印结果如下，因为我们设置的top_k=3，所以每个token都把排名前三的概率选出来了，同时<code>topk_indices</code>把这些概率对应的专家编号也选出来了，比如第0个token，激活了5号专家、3号专家、0号专家。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>topk_probs</span><span class=p>:</span>  <span class=n>tensor</span><span class=p>([[</span><span class=mf>0.2695</span><span class=p>,</span> <span class=mf>0.1714</span><span class=p>,</span> <span class=mf>0.1710</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mf>0.1679</span><span class=p>,</span> <span class=mf>0.1658</span><span class=p>,</span> <span class=mf>0.1556</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mf>0.2026</span><span class=p>,</span> <span class=mf>0.1715</span><span class=p>,</span> <span class=mf>0.1564</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mf>0.2827</span><span class=p>,</span> <span class=mf>0.1707</span><span class=p>,</span> <span class=mf>0.1236</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mf>0.2313</span><span class=p>,</span> <span class=mf>0.2149</span><span class=p>,</span> <span class=mf>0.1326</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mf>0.2278</span><span class=p>,</span> <span class=mf>0.1832</span><span class=p>,</span> <span class=mf>0.1512</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mf>0.1898</span><span class=p>,</span> <span class=mf>0.1598</span><span class=p>,</span> <span class=mf>0.1462</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mf>0.1952</span><span class=p>,</span> <span class=mf>0.1779</span><span class=p>,</span> <span class=mf>0.1648</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mf>0.2219</span><span class=p>,</span> <span class=mf>0.1463</span><span class=p>,</span> <span class=mf>0.1446</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mf>0.3554</span><span class=p>,</span> <span class=mf>0.1348</span><span class=p>,</span> <span class=mf>0.1264</span><span class=p>]])</span>
</span></span><span class=line><span class=cl><span class=n>topk_indices</span><span class=p>:</span>  <span class=n>tensor</span><span class=p>([[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>7</span><span class=p>]])</span></span></span></code></pre></td></tr></table></div></div><p>选择好专家后，就要开始计算了。计算规则是，对于每个token，假如它选择的专家是e1、e2、e3，概率分别是p1、p2、p3，那么这个token的计算结果就是 <code>p1*e1_out+p2*e2_out+p3*e3_out</code>。</p><div class="details admonition tips open disabled"><div class="details-summary admonition-title"><i class="icon fa-fw fa-solid fa-pencil-alt" aria-hidden=true></i>这里实际的 prob 应该还要进行归一化</div><div class=details-content><div class=admonition-content></div></div></div><p>由于计算个体是每个专家，所以代码中用for循环遍历每个专家。我们以第0个专家为例，看看它的计算过程是怎样的。首先需要确定0号专家的输入。由于不是每个token都选择了0号专家，所以不能把x直接作为输入，而是要确定一个下标向量idxes，把x[idxes]作为0号专家的输入，idxes的值就是激活了0号专家的所有token编号，那么怎么得到idxes呢？</p><p>首先计算一个mask：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>expert_mask</span> <span class=o>=</span> <span class=n>flat_indices</span> <span class=o>==</span> <span class=n>expert_idx</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 结果：</span>
</span></span><span class=line><span class=cl><span class=n>expert_mask</span><span class=p>:</span>  <span class=n>tensor</span><span class=p>([</span><span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span>  <span class=kc>True</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span>  <span class=kc>True</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>,</span> <span class=kc>False</span><span class=p>])</span></span></span></code></pre></td></tr></table></div></div><p><code>flat_indices</code>是<code>topk_indices</code>平铺之后的向量。通过对比，可以看到<code>expert_mask</code>中True的位置和<code>topk_indices</code>中0的位置铺平之后是一致的，代表第0个专家被第0个token和第1个token激活了。</p><p>而且<code>expert_mask</code>代表的含义是：只要它的第0-2的位置是True的话，就代表被第0个token激活了，只要它的第3-5的位置是True的话，就代表被第1个token激活了，以此类推，我们可以声明一个<code>sample_indices</code>向量：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>sample_indices</span><span class=p>:</span>  <span class=n>tensor</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=mi>8</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>9</span><span class=p>])</span></span></span></code></pre></td></tr></table></div></div><p>再通过下面的代码就可以把idxes、概率权重、输入都取出来了：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>expert_samples</span> <span class=o>=</span> <span class=n>sample_indices</span><span class=p>[</span><span class=n>expert_mask</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>expert_weights</span> <span class=o>=</span> <span class=n>flat_probs</span><span class=p>[</span><span class=n>expert_mask</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>expert_input</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>expert_samples</span><span class=p>]</span></span></span></code></pre></td></tr></table></div></div><p>再进行专家计算，并把计算结果叠加到对应的token上面去：：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>expert_output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>experts</span><span class=p>[</span><span class=n>expert_idx</span><span class=p>](</span><span class=n>expert_input</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>weighted_output</span> <span class=o>=</span> <span class=n>expert_output</span> <span class=o>*</span> <span class=n>expert_weights</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>outputs</span><span class=o>.</span><span class=n>index_add_</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>expert_samples</span><span class=p>,</span> <span class=n>weighted_output</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div><p>然后如果有配置共享专家，则会先经过共享专家，共享专家也是基本的MLP层，共享专家是一直激活的</p><div class="details admonition tip open disabled"><div class="details-summary admonition-title"><i class="icon fa-fw fa-regular fa-lightbulb" aria-hidden=true></i>在 DeepSeek-V3中，MoE层一般总共有256个路由专家，1个共享专家</div><div class=details-content><div class=admonition-content></div></div></div><p>MLP层一般会将 gate(w_1, 即经过激活函数的linear) 和 up(w_3)权重进行融合，形成 gate_up_proj(w_13)，而 down(w_2) 权重</p><p>DeepSeek MoE 架构的公式形式：</p><p><img loading=lazy src=https://cdn.ipfsscan.io/weibo/large/005wRZF3gy1i4lbc6xdmkj314009amxt.jpg alt=image></p><p>这里的公式其实结合上面代码理解非常简单，首先 $\mathbf{h}_t^l$ 是整个MoE部分的输出，其中 $\mathbf{u}_t^l$ 是经过MoE部分之前的输入，这里也是因为残差连接直接进行加和，而 $g_{i,t}$ 这一项是所有路由专家的加权计算结果，$g_{i,t}$ 表示每个选中的路由专家(top-k个)的<strong>用于加和</strong>的权重（并非本身FFN层的权重），而 $\text{FFN}_i(\mathbf{u}_t^l)$ 表示每个路由专家的计算结果。</p><p>那么这里的 $s_{i,t} = Softmax_i(\mathbf{u}_t^{l^T}e_i^l)$ 其实对应的代码就是：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>logits</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>gate</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>probs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div><p>这里 $e_i^l$ 论文中被称为可学习的参数，其实我理解就是 gate 这个线性层权重。</p><p>那么对于 DeepSeek-V3，gate部分有略微的改动：</p><p><img loading=lazy src=https://cdn.ipfsscan.io/weibo/large/005wRZF3gy1i4lbkkt9l1j30jz06imxb.jpg alt=image></p><p>了解了MoE的计算过程，接下来看看专家并行：</p><blockquote><p>参考文献：</p><ol><li><a href=https://zhuanlan.zhihu.com/p/1918753864556974722 target=_blank rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/1918753864556974722</a></li><li><a href=https://zhuanlan.zhihu.com/p/681154742 target=_blank rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/681154742</a></li></ol></blockquote><p><img loading=lazy src=https://cdn.ipfsscan.io/weibo/large/005wRZF3gy1i4lfix454vj31400z7ju5.jpg alt=image></p><p>专家并行的目标是将一个 MoE 层中的众多专家分布到不同的设备上，每个设备负责一部分专家。如果某个设备上的计算需要其他设备的专家，可以通过All2All通信实现。</p><p>专家并行思想来源论文：《GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding》</p><p>具体来说，MoE模型通常使用 Gating 模块来决定每个输入数据样本应该由哪些专家来处理。假设有一个输入数据样本位于设备 A 上，而 Gating 模块决定该样本应该由设备 B 和设备 C 上的专家来处理，那么就需要将该数据样本从设备 A 传输到设备 B 和设备 C。</p><p>标准 All-to-All</p><blockquote><p>在一个由 N 个节点组成的群体中，每一个节点都需要向其他 所有 N-1 个节点发送一份不同的数据，同时也需要从其他 所有 N-1 个节点接收一份不同的数据。</p></blockquote><p><img loading=lazy src=https://cdn.ipfsscan.io/weibo/large/005wRZF3gy1i4lc9g945kj31400gd0u0.jpg alt=image></p><p>非标准 All-to-All</p><p>简单来说就是有可能发送到不同设备的数据量不同，从不同设备接收的数据量也可能不同。</p><p><img loading=lazy src=https://cdn.ipfsscan.io/weibo/large/005wRZF3gy1i4lcgj6b17j30nd0f2gms.jpg alt=image></p><p>上述非标准 All2All 中有个问题：有些时候当前设备只知道要向其他设备发送多少数据，而并不知道需要从其他设备接收多少数据。</p><p>这个问题可以通过 2 次 all2all 来解决：</p><ul><li>第一次 all2all 交换要传输的数据量信息，这是一个标准的 all2all 操作。</li><li>第二次 all2all 根据上述获取的数据量信息来执行真正的数据传输，此时是一个非标准 all2all 操作。</li></ul><h2 id=mtp class=heading-element><span>MTP</span>
<a href=#mtp class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><h2 id=deepseek开源周 class=heading-element><span>DeepSeek开源周</span>
<a href=#deepseek%e5%bc%80%e6%ba%90%e5%91%a8 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><h3 id=flashmla class=heading-element><span>FlashMLA</span>
<a href=#flashmla class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h3 id=deepep class=heading-element><span>DeepEP</span>
<a href=#deepep class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h3 id=deepgemm class=heading-element><span>DeepGEMM</span>
<a href=#deepgemm class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h3 id=eplb class=heading-element><span>EPLB</span>
<a href=#eplb class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=背景动机 class=heading-element><span>背景动机</span>
<a href=#%e8%83%8c%e6%99%af%e5%8a%a8%e6%9c%ba class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>专家并行时，如何决定将那个专家放到哪张卡上。</p><p>考虑DeepSeek的EP，总共256个路由专家，1个共享专家.</p><p>prefill时,EP32, 256/32 = 8，每张卡放8个路由专家， 共享专家在所有卡上都复制一份，单卡总共9个专家。</p><p>decode时，EP144, 每张卡只放2个路由专家和一个共享专家，总共有 144 * 2-256 = 32个来放冗余路由专家。</p><p>需要解决的问题：</p><ol><li><p>怎么决定对哪些专家进行冗余？</p></li><li><p>冗余多少份？</p></li><li><p>对于任意一个专家，应该放在哪张卡上？</p></li></ol><p>EPLB 就是在解决上述问题。</p><p>逻辑专家：指模型中的256路由专家 + 1共享专家</p><p>物理专家：指经过冗余后实际部署到GPU上的专家, 数量大于 256 + 1</p><p><a href=https://zhuanlan.zhihu.com/p/27181462601 target=_blank rel="external nofollow noopener noreferrer">DeepSeek 推理系统概览</a></p><blockquote><p><strong>Prefill</strong>：路由专家 EP32、MLA 和共享专家 DP32，一个部署单元是 4 节点，32 个冗余路由专家，每张卡 9 个路由专家和 1 个共享专家</p></blockquote><blockquote><p><strong>Decode</strong>：路由专家 EP144、MLA 和共享专家 DP144，一个部署单元是 18 节点，32 个冗余路由专家，每张卡 2 个路由专家和 1 个共享专家</p></blockquote><p>官网例子：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>eplb</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 这里的weight是记录每一个专家历史工作负载，来评估每个专家的“热门”程度</span>
</span></span><span class=line><span class=cl><span class=n>weight</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span> <span class=mi>90</span><span class=p>,</span> <span class=mi>132</span><span class=p>,</span>  <span class=mi>40</span><span class=p>,</span>  <span class=mi>61</span><span class=p>,</span> <span class=mi>104</span><span class=p>,</span> <span class=mi>165</span><span class=p>,</span>  <span class=mi>39</span><span class=p>,</span>   <span class=mi>4</span><span class=p>,</span>  <span class=mi>73</span><span class=p>,</span>  <span class=mi>56</span><span class=p>,</span> <span class=mi>183</span><span class=p>,</span>  <span class=mi>86</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                       <span class=p>[</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>107</span><span class=p>,</span> <span class=mi>104</span><span class=p>,</span>  <span class=mi>64</span><span class=p>,</span>  <span class=mi>19</span><span class=p>,</span> <span class=mi>197</span><span class=p>,</span> <span class=mi>187</span><span class=p>,</span> <span class=mi>157</span><span class=p>,</span> <span class=mi>172</span><span class=p>,</span>  <span class=mi>86</span><span class=p>,</span>  <span class=mi>16</span><span class=p>,</span>  <span class=mi>27</span><span class=p>]])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>num_replicas</span> <span class=o>=</span> <span class=mi>16</span>  <span class=c1># 实际可以放置的总物理专家数量</span>
</span></span><span class=line><span class=cl><span class=n>num_groups</span> <span class=o>=</span> <span class=mi>4</span>     <span class=c1># 对总卡数进行分组</span>
</span></span><span class=line><span class=cl><span class=n>num_nodes</span> <span class=o>=</span> <span class=mi>2</span>      <span class=c1># 节点总数</span>
</span></span><span class=line><span class=cl><span class=n>num_gpus</span> <span class=o>=</span> <span class=mi>8</span>       <span class=c1># 卡总数</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>phy2log</span><span class=p>,</span> <span class=n>log2phy</span><span class=p>,</span> <span class=n>logcnt</span> <span class=o>=</span> <span class=n>eplb</span><span class=o>.</span><span class=n>rebalance_experts</span><span class=p>(</span><span class=n>weight</span><span class=p>,</span> <span class=n>num_replicas</span><span class=p>,</span> <span class=n>num_groups</span><span class=p>,</span> <span class=n>num_nodes</span><span class=p>,</span> <span class=n>num_gpus</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>phy2log</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 最后输出负载均衡后的推荐放置方案</span>
</span></span><span class=line><span class=cl><span class=c1># Output:</span>
</span></span><span class=line><span class=cl><span class=c1># tensor([[ 5,  6,  5,  7,  8,  4,  3,  4, 10,  9, 10,  2,  0,  1, 11,  1],</span>
</span></span><span class=line><span class=cl><span class=c1>#         [ 7, 10,  6,  8,  6, 11,  8,  9,  2,  4,  5,  1,  5,  0,  3,  1]])</span></span></span></code></pre></td></tr></table></div></div><p>该示例展示了一个两层的 MoE 模型，每层包含 12 个专家。每层引入 4 个冗余专家，总共 16 个副本被放置在 2 个节点上，每个节点包含4个 GPU。输出结果展示了专家复制和放置的计划。</p><p><img loading=lazy src=https://cdn.ipfsscan.io/weibo/large/005wRZF3gy1i4lphi3qmgj314006pt9t.jpg alt=image></p><h4 id=eplb核心函数 class=heading-element><span>EPLB核心函数</span>
<a href=#eplb%e6%a0%b8%e5%bf%83%e5%87%bd%e6%95%b0 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>balanced_packing</span><span class=p>(</span><span class=n>weight</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span> <span class=n>num_packs</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Tuple</span><span class=p>[</span><span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Pack n weighted objects to m packs, such that each bin contains exactly n/m objects and the weights of all packs
</span></span></span><span class=line><span class=cl><span class=s2>    are as balanced as possible.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Parameters:
</span></span></span><span class=line><span class=cl><span class=s2>        weight: [X, n], the weight of each item
</span></span></span><span class=line><span class=cl><span class=s2>        num_packs: number of packs
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        pack_index: [X, n], the pack index of each item
</span></span></span><span class=line><span class=cl><span class=s2>        rank_in_pack: [X, n], the rank of the item in the pack
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>num_layers</span><span class=p>,</span> <span class=n>num_groups</span> <span class=o>=</span> <span class=n>weight</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>num_groups</span> <span class=o>%</span> <span class=n>num_packs</span> <span class=o>==</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>groups_per_pack</span> <span class=o>=</span> <span class=n>num_groups</span> <span class=o>//</span> <span class=n>num_packs</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>groups_per_pack</span> <span class=o>==</span> <span class=mi>1</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>pack_index</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>weight</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int64</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>weight</span><span class=o>.</span><span class=n>device</span><span class=p>)</span><span class=o>.</span><span class=n>expand</span><span class=p>(</span><span class=n>weight</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>rank_in_pack</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros_like</span><span class=p>(</span><span class=n>weight</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int64</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>pack_index</span><span class=p>,</span> <span class=n>rank_in_pack</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>indices</span> <span class=o>=</span> <span class=n>weight</span><span class=o>.</span><span class=n>float</span><span class=p>()</span><span class=o>.</span><span class=n>sort</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>descending</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span><span class=o>.</span><span class=n>indices</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>pack_index</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>full_like</span><span class=p>(</span><span class=n>weight</span><span class=p>,</span> <span class=n>fill_value</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int64</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>rank_in_pack</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>full_like</span><span class=p>(</span><span class=n>pack_index</span><span class=p>,</span> <span class=n>fill_value</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_layers</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>pack_weights</span> <span class=o>=</span> <span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>num_packs</span>
</span></span><span class=line><span class=cl>        <span class=n>pack_items</span> <span class=o>=</span> <span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>num_packs</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>group</span> <span class=ow>in</span> <span class=n>indices</span><span class=p>[</span><span class=n>i</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>            <span class=n>pack</span> <span class=o>=</span> <span class=nb>min</span><span class=p>((</span><span class=n>i</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_packs</span><span class=p>)</span> <span class=k>if</span> <span class=n>pack_items</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>&lt;</span> <span class=n>groups_per_pack</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                       <span class=n>key</span><span class=o>=</span><span class=n>pack_weights</span><span class=o>.</span><span class=fm>__getitem__</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>assert</span> <span class=n>pack_items</span><span class=p>[</span><span class=n>pack</span><span class=p>]</span> <span class=o>&lt;</span> <span class=n>groups_per_pack</span>
</span></span><span class=line><span class=cl>            <span class=n>pack_index</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=n>group</span><span class=p>]</span> <span class=o>=</span> <span class=n>pack</span>
</span></span><span class=line><span class=cl>            <span class=n>rank_in_pack</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=n>group</span><span class=p>]</span> <span class=o>=</span> <span class=n>pack_items</span><span class=p>[</span><span class=n>pack</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>pack_weights</span><span class=p>[</span><span class=n>pack</span><span class=p>]</span> <span class=o>+=</span> <span class=n>weight</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=n>group</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>pack_items</span><span class=p>[</span><span class=n>pack</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>pack_index</span><span class=p>,</span> <span class=n>rank_in_pack</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>replicate_experts</span><span class=p>(</span><span class=n>weight</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span> <span class=n>num_phy</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Tuple</span><span class=p>[</span><span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Replicate `num_log` experts to `num_phy` replicas, such that the maximum load of all replicas is minimized.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Parameters:
</span></span></span><span class=line><span class=cl><span class=s2>        weight: [X, num_log]
</span></span></span><span class=line><span class=cl><span class=s2>        num_phy: total number of experts after replication
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        phy2log: [X, num_phy], logical expert id of each physical expert
</span></span></span><span class=line><span class=cl><span class=s2>        rank: [X, num_phy], the replica rank
</span></span></span><span class=line><span class=cl><span class=s2>        logcnt: [X, num_log], number of replicas for each logical expert
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>n</span><span class=p>,</span> <span class=n>num_log</span> <span class=o>=</span> <span class=n>weight</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>    <span class=n>num_redundant</span> <span class=o>=</span> <span class=n>num_phy</span> <span class=o>-</span> <span class=n>num_log</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>num_redundant</span> <span class=o>&gt;=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>device</span> <span class=o>=</span> <span class=n>weight</span><span class=o>.</span><span class=n>device</span>
</span></span><span class=line><span class=cl>    <span class=n>phy2log</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>num_phy</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int64</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span><span class=o>.</span><span class=n>repeat</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>rank</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>num_phy</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int64</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logcnt</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>num_log</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int64</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>arangen</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int64</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_log</span><span class=p>,</span> <span class=n>num_phy</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>redundant_indices</span> <span class=o>=</span> <span class=p>(</span><span class=n>weight</span> <span class=o>/</span> <span class=n>logcnt</span><span class=p>)</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>indices</span>
</span></span><span class=line><span class=cl>        <span class=n>phy2log</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>redundant_indices</span>
</span></span><span class=line><span class=cl>        <span class=n>rank</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>logcnt</span><span class=p>[</span><span class=n>arangen</span><span class=p>,</span> <span class=n>redundant_indices</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>logcnt</span><span class=p>[</span><span class=n>arangen</span><span class=p>,</span> <span class=n>redundant_indices</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>phy2log</span><span class=p>,</span> <span class=n>rank</span><span class=p>,</span> <span class=n>logcnt</span></span></span></code></pre></td></tr></table></div></div><h4 id=核心api class=heading-element><span>核心API</span>
<a href=#%e6%a0%b8%e5%bf%83api class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 分层均衡</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>rebalance_experts_hierarchical</span><span class=p>(</span><span class=n>weight</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span> <span class=n>num_physical_experts</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                      <span class=n>num_groups</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span> <span class=n>num_nodes</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span> <span class=n>num_gpus</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Parameters:
</span></span></span><span class=line><span class=cl><span class=s2>        weight: [num_moe_layers, num_logical_experts]
</span></span></span><span class=line><span class=cl><span class=s2>        num_physical_experts: number of physical experts after replication
</span></span></span><span class=line><span class=cl><span class=s2>        num_groups: number of expert groups
</span></span></span><span class=line><span class=cl><span class=s2>        num_nodes: number of server nodes, where the intra-node network (e.g, NVLink) is faster
</span></span></span><span class=line><span class=cl><span class=s2>        num_gpus: number of GPUs, must be a multiple of `num_nodes`
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        physical_to_logical_map: [num_moe_layers, num_physical_experts]
</span></span></span><span class=line><span class=cl><span class=s2>        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]
</span></span></span><span class=line><span class=cl><span class=s2>        logical_count: [num_moe_layers, num_logical_experts]
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>num_layers</span><span class=p>,</span> <span class=n>num_logical_experts</span> <span class=o>=</span> <span class=n>weight</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>num_logical_experts</span> <span class=o>%</span> <span class=n>num_groups</span> <span class=o>==</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>group_size</span> <span class=o>=</span> <span class=n>num_logical_experts</span> <span class=o>//</span> <span class=n>num_groups</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>num_groups</span> <span class=o>%</span> <span class=n>num_nodes</span> <span class=o>==</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>groups_per_node</span> <span class=o>=</span> <span class=n>num_groups</span> <span class=o>//</span> <span class=n>num_nodes</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>num_gpus</span> <span class=o>%</span> <span class=n>num_nodes</span> <span class=o>==</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>num_physical_experts</span> <span class=o>%</span> <span class=n>num_gpus</span> <span class=o>==</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>phy_experts_per_gpu</span> <span class=o>=</span> <span class=n>num_physical_experts</span> <span class=o>//</span> <span class=n>num_gpus</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>inverse</span><span class=p>(</span><span class=n>perm</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>inv</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>empty_like</span><span class=p>(</span><span class=n>perm</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>inv</span><span class=o>.</span><span class=n>scatter_</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>perm</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>perm</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>1</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int64</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>perm</span><span class=o>.</span><span class=n>device</span><span class=p>)</span><span class=o>.</span><span class=n>expand</span><span class=p>(</span><span class=n>perm</span><span class=o>.</span><span class=n>shape</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>inv</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Step 1: 将专家组均匀分配到各个节点，确保不同节点的负载平衡</span>
</span></span><span class=line><span class=cl>    <span class=c1># 将权重矩阵按组进行展开并计算每组的总负载</span>
</span></span><span class=line><span class=cl>    <span class=n>tokens_per_group</span> <span class=o>=</span> <span class=n>weight</span><span class=o>.</span><span class=n>unflatten</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=p>(</span><span class=n>num_groups</span><span class=p>,</span> <span class=n>group_size</span><span class=p>))</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 使用 balanced_packing 函数将专家组打包到节点上，</span>
</span></span><span class=line><span class=cl>    <span class=c1># 得到每个组所在的节点索引和在该节点内的排名</span>
</span></span><span class=line><span class=cl>    <span class=n>group_pack_index</span><span class=p>,</span> <span class=n>group_rank_in_pack</span> <span class=o>=</span> <span class=n>balanced_packing</span><span class=p>(</span><span class=n>tokens_per_group</span><span class=p>,</span> <span class=n>num_nodes</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 计算逻辑专家到中间逻辑专家的映射</span>
</span></span><span class=line><span class=cl>    <span class=n>log2mlog</span> <span class=o>=</span> <span class=p>(((</span><span class=n>group_pack_index</span> <span class=o>*</span> <span class=n>groups_per_node</span> <span class=o>+</span> <span class=n>group_rank_in_pack</span><span class=p>)</span> <span class=o>*</span> <span class=n>group_size</span><span class=p>)</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=o>+</span>
</span></span><span class=line><span class=cl>                <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>group_size</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int64</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>group_pack_index</span><span class=o>.</span><span class=n>device</span><span class=p>))</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 计算中间逻辑专家到逻辑专家的逆映射</span>
</span></span><span class=line><span class=cl>    <span class=n>mlog2log</span> <span class=o>=</span> <span class=n>inverse</span><span class=p>(</span><span class=n>log2mlog</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Step 2: 在每个节点内复制专家，以最小化所有副本的最大负载。</span>
</span></span><span class=line><span class=cl>    <span class=c1># [num_layers * num_nodes, num_logical_experts // num_nodes]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 根据中间逻辑专家到逻辑专家的映射，重新排列权重矩阵，并按节点进行分组</span>
</span></span><span class=line><span class=cl>    <span class=n>tokens_per_mlog</span> <span class=o>=</span> <span class=n>weight</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>mlog2log</span><span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>num_logical_experts</span> <span class=o>//</span> <span class=n>num_nodes</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 使用 replicate_experts 函数在每个节点内复制专家，</span>
</span></span><span class=line><span class=cl>    <span class=c1># 得到物理专家到中间逻辑专家的映射、物理专家的排名和每个中间逻辑专家的副本数</span>
</span></span><span class=line><span class=cl>    <span class=n>phy2mlog</span><span class=p>,</span> <span class=n>phyrank</span><span class=p>,</span> <span class=n>mlogcnt</span> <span class=o>=</span> <span class=n>replicate_experts</span><span class=p>(</span><span class=n>tokens_per_mlog</span><span class=p>,</span> <span class=n>num_physical_experts</span> <span class=o>//</span> <span class=n>num_nodes</span><span class=p>)</span>    
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Step 3: 将复制后的专家分配到各个 GPU 上，确保不同 GPU 的负载平衡。</span>
</span></span><span class=line><span class=cl>    <span class=c1># [num_layers * num_nodes, num_physical_experts // num_nodes]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 计算每个物理专家的负载</span>
</span></span><span class=line><span class=cl>    <span class=n>tokens_per_phy</span> <span class=o>=</span> <span class=p>(</span><span class=n>tokens_per_mlog</span> <span class=o>/</span> <span class=n>mlogcnt</span><span class=p>)</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>phy2mlog</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 使用 balanced_packing 函数将物理专家打包到每个节点内的 GPU 上，</span>
</span></span><span class=line><span class=cl>    <span class=c1># 得到每个物理专家所在的 GPU 索引和在该 GPU 内的排名</span>
</span></span><span class=line><span class=cl>    <span class=n>pack_index</span><span class=p>,</span> <span class=n>rank_in_pack</span> <span class=o>=</span> <span class=n>balanced_packing</span><span class=p>(</span><span class=n>tokens_per_phy</span><span class=p>,</span> <span class=n>num_gpus</span> <span class=o>//</span> <span class=n>num_nodes</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 计算物理专家到最终物理专家的映射</span>
</span></span><span class=line><span class=cl>    <span class=n>phy2pphy</span> <span class=o>=</span> <span class=n>pack_index</span> <span class=o>*</span> <span class=n>phy_experts_per_gpu</span> <span class=o>+</span> <span class=n>rank_in_pack</span>
</span></span><span class=line><span class=cl>    <span class=c1># 计算最终物理专家到物理专家的逆映射</span>
</span></span><span class=line><span class=cl>    <span class=n>pphy2phy</span> <span class=o>=</span> <span class=n>inverse</span><span class=p>(</span><span class=n>phy2pphy</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 根据最终物理专家到物理专家的映射，重新排列物理专家到中间逻辑专家的映射</span>
</span></span><span class=line><span class=cl>    <span class=n>pphy2mlog</span> <span class=o>=</span> <span class=n>phy2mlog</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>pphy2phy</span><span class=p>)</span> <span class=c1># [num_layers * num_nodes, num_log_per_nodes]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 调整 pphy2mlog 的形状，使其包含所有节点的信息</span>
</span></span><span class=line><span class=cl>    <span class=n>pphy2mlog</span> <span class=o>=</span> <span class=p>(</span><span class=n>pphy2mlog</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>num_layers</span><span class=p>,</span> <span class=n>num_nodes</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=o>+</span>
</span></span><span class=line><span class=cl>                 <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>num_logical_experts</span><span class=p>,</span> <span class=n>num_logical_experts</span> <span class=o>//</span> <span class=n>num_nodes</span><span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 根据中间逻辑专家到逻辑专家的映射，将 pphy2mlog 转换为最终物理专家到逻辑专家的映射  </span>
</span></span><span class=line><span class=cl>    <span class=n>pphy2log</span> <span class=o>=</span> <span class=n>mlog2log</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>pphy2mlog</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 根据最终物理专家到物理专家的映射，重新排列物理专家的排名</span>
</span></span><span class=line><span class=cl>    <span class=n>pphyrank</span> <span class=o>=</span> <span class=n>phyrank</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>pphy2phy</span><span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>num_layers</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 根据逻辑专家到中间逻辑专家的映射，计算每个逻辑专家的副本数</span>
</span></span><span class=line><span class=cl>    <span class=n>logcnt</span> <span class=o>=</span> <span class=n>mlogcnt</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>num_layers</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>log2mlog</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>pphy2log</span><span class=p>,</span> <span class=n>pphyrank</span><span class=p>,</span> <span class=n>logcnt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 全局均衡（适用于推理时更高的专家并行度）</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>rebalance_experts</span><span class=p>(</span><span class=n>weight</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span> <span class=n>num_replicas</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span> <span class=n>num_groups</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                      <span class=n>num_nodes</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span> <span class=n>num_gpus</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Tuple</span><span class=p>[</span><span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Entry point for expert-parallelism load balancer.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Parameters:
</span></span></span><span class=line><span class=cl><span class=s2>        weight: [layers, num_logical_experts], the load statistics for all logical experts
</span></span></span><span class=line><span class=cl><span class=s2>        num_replicas: number of physical experts, must be a multiple of `num_gpus`
</span></span></span><span class=line><span class=cl><span class=s2>        num_groups: number of expert groups
</span></span></span><span class=line><span class=cl><span class=s2>        num_nodes: number of server nodes, where the intra-node network (e.g, NVLink) is faster
</span></span></span><span class=line><span class=cl><span class=s2>        num_gpus: number of GPUs, must be a multiple of `num_nodes`
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        physical_to_logical_map: [layers, num_replicas], the expert index of each replica
</span></span></span><span class=line><span class=cl><span class=s2>        logical_to_physical_map: [layers, num_logical_experts, X], the replica indices for each expert
</span></span></span><span class=line><span class=cl><span class=s2>        expert_count: [layers, num_logical_experts], number of physical replicas for each logical expert
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>num_layers</span><span class=p>,</span> <span class=n>num_logical_experts</span> <span class=o>=</span> <span class=n>weight</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>    <span class=n>weight</span> <span class=o>=</span> <span class=n>weight</span><span class=o>.</span><span class=n>float</span><span class=p>()</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>num_groups</span> <span class=o>%</span> <span class=n>num_nodes</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># use hierarchical load-balance policy</span>
</span></span><span class=line><span class=cl>        <span class=n>phy2log</span><span class=p>,</span> <span class=n>phyrank</span><span class=p>,</span> <span class=n>logcnt</span> <span class=o>=</span> <span class=n>rebalance_experts_hierarchical</span><span class=p>(</span><span class=n>weight</span><span class=p>,</span> <span class=n>num_replicas</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                                                  <span class=n>num_groups</span><span class=p>,</span> <span class=n>num_nodes</span><span class=p>,</span> <span class=n>num_gpus</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># use global load-balance policy</span>
</span></span><span class=line><span class=cl>        <span class=n>phy2log</span><span class=p>,</span> <span class=n>phyrank</span><span class=p>,</span> <span class=n>logcnt</span> <span class=o>=</span> <span class=n>rebalance_experts_hierarchical</span><span class=p>(</span><span class=n>weight</span><span class=p>,</span> <span class=n>num_replicas</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>num_gpus</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>maxlogcnt</span> <span class=o>=</span> <span class=n>logcnt</span><span class=o>.</span><span class=n>max</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>log2phy</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>full</span><span class=p>((</span><span class=n>num_layers</span><span class=p>,</span> <span class=n>num_logical_experts</span><span class=p>,</span> <span class=n>maxlogcnt</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                                       <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int64</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>logcnt</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>log2phy</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>num_layers</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>scatter_</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>phy2log</span> <span class=o>*</span> <span class=n>maxlogcnt</span> <span class=o>+</span> <span class=n>phyrank</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>num_replicas</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>int64</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>log2phy</span><span class=o>.</span><span class=n>device</span><span class=p>)</span><span class=o>.</span><span class=n>expand</span><span class=p>(</span><span class=n>num_layers</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>phy2log</span><span class=p>,</span> <span class=n>log2phy</span><span class=p>,</span> <span class=n>logcnt</span></span></span></code></pre></td></tr></table></div></div></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="更新于 2025-08-14 00:15:18">更新于 2025-08-14&nbsp;</span></div></div><div class=post-info-line><div class=post-info-md><span><a href=/2025/d01413e/index.md title=阅读原始文档 class=link-to-markdown>阅读原始文档</a></span></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 Pocket" data-sharer=pocket data-url=https://yitaonote.com/2025/d01413e/><i class="fa-brands fa-get-pocket fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=https://yitaonote.com/2025/d01413e/ data-title=DeepSeek相关优化技术><i class="fa-brands fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/2025/a793bc7/ class=post-nav-item rel=prev title=量化><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>量化</a><a href=/2025/39b641b/ class=post-nav-item rel=next title=Softmax与Flash-Attention>Softmax与Flash-Attention<i class="fa-solid fa-angle-right fa-fw" aria-hidden=true></i></a></div></div><div class=post-reward><div class=comment></div><input type=checkbox class=reward-input name=reward id=fi-reward hidden>
<label class=reward-button for=fi-reward><i class="fa-solid fa-qrcode fa-fw" aria-hidden=true></i>赞赏</label><div class=reward-ways data-mode=static><div><img src=https://cdn.ipfsscan.io/weibo/large/005wRZF3ly1i429ilg93xj30u018zjut.jpg alt="yitao 支付宝"><span>支付宝</span></div><div><img src=https://cdn.ipfsscan.io/weibo/large/005wRZF3ly1i429iozq5hj30n00v8gne.jpg alt="yitao 微信"><span>微信</span></div></div></div><div id=comments><div id=giscus class=comment><script src=https://giscus.app/client.js data-repo=walker-ai/walker-ai.github.io data-repo-id=R_kgDOOM9c8w data-category=Announcements data-category-id=DIC_kwDOOM9c884CoX_P data-mapping=pathname data-strict=0 data-theme=preferred_color_scheme data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-lang=zh-CN data-loading=lazy crossorigin=anonymous async defer></script></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://giscus.app/ rel="external nofollow noopener noreferrer">giscus</a>.</noscript></div></article><aside class=toc id=toc-auto aria-label=目录><h2 class=toc-title>目录&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden=true></i></h2><div class=toc-content id=toc-content-auto></div></aside></main><footer class=footer><div class=footer-container><div class="footer-line powered">由 <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.145.0"><img class=hugo-icon src=/images/hugo.min.svg alt="Hugo logo"> Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/hugo-fixit/FixIt target=_blank rel=external title="FixIt v0.3.17-8212d6fd"><img class=fixit-icon src=/images/fixit.min.svg alt="FixIt logo"> FixIt</a></div><div class="footer-line copyright" itemscope itemtype=http://schema.org/CreativeWork><i class="fa-regular fa-copyright fa-fw" aria-hidden=true></i>
<span itemprop=copyrightYear>2018 - 2025</span><span class=author itemprop=copyrightHolder>
<a href=/></a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label=回到顶部><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class="variant-numeric d-none">0%</span></div><div class="fixed-button view-comments d-none" role=button aria-label=查看评论><i class="fa-solid fa-comment fa-fw" aria-hidden=true></i></div></div><a href=https://github.com/walker-ai/walker-ai.github.io title="View source on GitHub" target=_blank rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true" width="56" height="56"><path d="M0 0 115 115h15l12 27L250 250V0z"/><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentcolor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4l13.9-13.8C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8z" fill="currentcolor" class="octo-body"/></svg></a><div id=mask></div><div class=reading-progress-bar style=left:0;top:0></div><noscript><div class=noscript-warning>该网站在启用 JavaScript 的情况下效果最佳。</div></noscript></div><link rel=preload href=https://unpkg.com/katex@0.16.10/dist/katex.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://unpkg.com/katex@0.16.10/dist/katex.min.css></noscript><link rel=stylesheet href=https://unpkg.com/pace-js@1.2.4/themes/blue/pace-theme-minimal.css><script src=https://unpkg.com/autocomplete.js@0.38.1/dist/autocomplete.min.js defer></script><script src=https://unpkg.com/fuse.js@6.6.2/dist/fuse.min.js defer></script><script src=https://unpkg.com/twemoji@14.0.2/dist/twemoji.min.js defer></script><script src=https://unpkg.com/sharer.js@0.5.1/sharer.min.js async defer></script><script src=https://unpkg.com/katex@0.16.10/dist/katex.min.js defer></script><script src=https://unpkg.com/katex@0.16.10/dist/contrib/auto-render.min.js defer></script><script src=https://unpkg.com/katex@0.16.10/dist/contrib/mhchem.min.js defer></script><script src=https://unpkg.com/pangu@4.0.7/dist/browser/pangu.min.js defer></script><script src=https://unpkg.com/pace-js@1.2.4/pace.min.js async defer></script><script>window.config={code:{copyTitle:"复制到剪贴板",maxShownLines:100},comment:{enable:!0,expired:!1,giscus:{darkTheme:"dark",lightTheme:"light",origin:"https://giscus.app"}},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},pangu:{enable:!0,selector:"article"},search:{distance:100,findAllMatches:!1,fuseIndexURL:"/search.json",highlightTag:"em",ignoreFieldNorm:!1,ignoreLocation:!1,isCaseSensitive:!1,location:0,maxResultLength:10,minMatchCharLength:2,noResultsFound:"没有找到结果",snippetLength:30,threshold:.3,type:"fuse",useExtendedSearch:!1},twemoji:!0,version:"v0.3.17-8212d6fd"}</script><script src=/js/theme.min.js defer></script></body></html>