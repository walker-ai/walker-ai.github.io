[{"categories":["八股"],"content":"《现代C++并发编程教程》 —— C++并发编程学习笔记（三） ","date":"2025-03-24","objectID":"/2025/80f2e62/:0:0","tags":["C++"],"title":"并发编程（三）","uri":"/2025/80f2e62/"},{"categories":["八股"],"content":"原子操作 这里只简单介绍 std::atomic\u003cbool\u003e（包含在 \u003catomic\u003e 中），最基本的整数原子类型。虽然同样不可复制不可移动，但可以使用非原子的 bool 类型进行构造，初始化为 true 或 false，并且能从非原子的 bool 对象赋值给 std::atomic\u003cbool\u003e： std::atomic\u003cbool\u003e b{ true }; b = false; ","date":"2025-03-24","objectID":"/2025/80f2e62/:1:0","tags":["C++"],"title":"并发编程（三）","uri":"/2025/80f2e62/"},{"categories":["八股"],"content":"线程池 抽象的来说，可以当做是一个池子中存放了一堆线程，故称作线程池。简而言之，线程池是指代一组预先创建的、可以复用的线程集合。这些线程由线程池管理，用于执行多个任务而无需频繁地创建和销毁线程。 这是一个典型的线程池结构。线程池包含一个任务队列，当有新任务加入时，调度器会将任务分配给线程池中的空闲线程进行执行。线程在执行完任务后会进入休眠状态，等待调度器的下一次唤醒。当有新的任务加入队列，并且有线程处于休眠状态时，调度器会唤醒休眠的线程，并分配新的任务给它们执行。线程执行完新任务后，会再次进入休眠状态，直到有新的任务到来，调度器才可能会再次唤醒它们。 图中线程1 就是被调度器分配了任务1，执行完毕后休眠，然而新任务的到来让调度器再次将它唤醒，去执行任务6，执行完毕后继续休眠。 使用线程池的益处我们已经加粗了，然而这其实并不是“线程池”独有的，任何创建和销毁存在较大开销的设施，都可以进行所谓的“池化”。 常见的还有：套接字连接池、数据库连接池、内存池、对象池。 下面简单介绍下常用的线程池。 ","date":"2025-03-24","objectID":"/2025/80f2e62/:2:0","tags":["C++"],"title":"并发编程（三）","uri":"/2025/80f2e62/"},{"categories":["八股"],"content":"boost::asio::thread_pool boost::asio::thread_pool 是 Boost.Asio 库提供的一种线程池实现。 Asio 是一个跨平台的 C++ 库，用于网络和低级 I/O 编程，使用 现代C++ 方法为开发人员提供一致的异步模型。 使用方法： 创建线程池对象，指定或让 Asio 自动决定线程数量。 提交任务：通过 boost::asio::post 函数模板提交任务到线程池中。 阻塞，直到池中的线程完成任务。 #include \u003cboost/asio.hpp\u003e #include \u003ciostream\u003e std::mutex m; void print_task(int n) { std::lock_guard\u003cstd::mutex\u003e lc{ m }; std::cout \u003c\u003c \"Task \" \u003c\u003c n \u003c\u003c \" is running on thr: \" \u003c\u003c std::this_thread::get_id() \u003c\u003c '\\n'; } int main() { boost::asio::thread_pool pool{ 4 }; // 创建一个包含 4 个线程的线程池 for (int i = 0; i \u003c 10; ++i) { boost::asio::post(pool, [i] { print_task(i); }); } pool.join(); // 等待所有任务执行完成 } 详情见 boost/asio 的使用，这里不再展开。 ","date":"2025-03-24","objectID":"/2025/80f2e62/:2:1","tags":["C++"],"title":"并发编程（三）","uri":"/2025/80f2e62/"},{"categories":["八股"],"content":"实现线程池 实现一个普通的能够满足日常开发需求的线程池实际上非常简单，只需要不到一百行代码。其实绝大部分开发者使用线程池，只是为了不重复多次创建线程罢了。所以只需要一个提供一个外部接口，可以传入任务到任务队列，然后安排线程去执行。无非是使用条件变量、互斥量、原子标志位，这些东西，就足够编写一个满足绝大部分业务需求的线程池。 我们先编写一个最基础的线程池，首先确定它的数据成员： class ThreadPool { std::mutex mutex_; // 用于保护共享资源（如任务队列）在多线程环境中的访问，避免数据竞争。 std::condition_variable cv_; // 用于线程间的同步，允许线程等待特定条件（如新任务加入队列）并在条件满足时唤醒线程。 std::atomic\u003cbool\u003e stop_; // 指示线程池是否停止。 std::atomic\u003cstd::size_t\u003e num_threads_; // 表示线程池中的线程数量。 std::queue\u003cTask\u003e tasks_; // 任务队列，存储等待执行的任务，任务按提交顺序执行。 std::vector\u003cstd::thread\u003e pool_; // 线程容器，存储管理线程对象，每个线程从任务队列中获取任务并执行。 }; 标头依赖： #include \u003ciostream\u003e #include \u003cthread\u003e #include \u003cmutex\u003e #include \u003ccondition_variable\u003e #include \u003cfuture\u003e #include \u003catomic\u003e #include \u003cqueue\u003e #include \u003cvector\u003e #include \u003csyncstream\u003e #include \u003cfunctional\u003e 提供构造析构函数，以及一些外部接口：submit()、start()、stop()、join()，也就完成了： inline std::size_t default_thread_pool_size()noexcept { std::size_t num_threads = std::thread::hardware_concurrency() * 2; num_threads = num_threads == 0 ? 2 : num_threads; return num_threads; } class ThreadPool { public: using Task = std::packaged_task\u003cvoid()\u003e; ThreadPool(const ThreadPool\u0026) = delete; ThreadPool\u0026 operator=(const ThreadPool\u0026) = delete; ThreadPool(std::size_t num_thread = default_thread_pool_size()) : stop_{ false }, num_threads_{ num_thread } { start(); } ~ThreadPool() { stop(); } void stop() { stop_.store(true); cv_.notify_all(); for (auto\u0026 thread : pool_) { if (thread.joinable()) { thread.join(); } } pool_.clear(); } template\u003ctypename F, typename... Args\u003e std::future\u003cstd::invoke_result_t\u003cstd::decay_t\u003cF\u003e, std::decay_t\u003cArgs\u003e...\u003e\u003e submit(F\u0026\u0026 f, Args\u0026\u0026...args) { using RetType = std::invoke_result_t\u003cstd::decay_t\u003cF\u003e, std::decay_t\u003cArgs\u003e...\u003e; if (stop_.load()) { throw std::runtime_error(\"ThreadPool is stopped\"); } auto task = std::make_shared\u003cstd::packaged_task\u003cRetType()\u003e\u003e( std::bind(std::forward\u003cF\u003e(f), std::forward\u003cArgs\u003e(args)...)); std::future\u003cRetType\u003e ret = task-\u003eget_future(); { std::lock_guard\u003cstd::mutex\u003e lc{ mutex_ }; tasks_.emplace([task] {(*task)(); }); } cv_.notify_one(); return ret; } void start() { for (std::size_t i = 0; i \u003c num_threads_; ++i) { pool_.emplace_back([this] { while (!stop_) { Task task; { std::unique_lock\u003cstd::mutex\u003e lc{ mutex_ }; cv_.wait(lc, [this] {return stop_ || !tasks_.empty(); }); if (tasks_.empty()) return; task = std::move(tasks_.front()); tasks_.pop(); } task(); } }); } } private: std::mutex mutex_; std::condition_variable cv_; std::atomic\u003cbool\u003e stop_; std::atomic\u003cstd::size_t\u003e num_threads_; std::queue\u003cTask\u003e tasks_; std::vector\u003cstd::thread\u003e pool_; }; 测试 demo: int main() { ThreadPool pool{ 4 }; // 创建一个有 4 个线程的线程池 std::vector\u003cstd::future\u003cint\u003e\u003e futures; // future 集合，获取返回值 for (int i = 0; i \u003c 10; ++i) { futures.emplace_back(pool.submit(print_task, i)); } for (int i = 0; i \u003c 10; ++i) { futures.emplace_back(pool.submit(print_task2, i)); } int sum = 0; for (auto\u0026 future : futures) { sum += future.get(); // get() 成员函数 阻塞到任务执行完毕，获取返回值 } std::cout \u003c\u003c \"sum: \" \u003c\u003c sum \u003c\u003c '\\n'; } // 析构自动 stop() 可能的运行结果： Task 0 is running on thr: 6900 Task 1 is running on thr: 36304 Task 5 is running on thr: 36304 Task 3 is running on thr: 6900 Task 7 is running on thr: 6900 Task 2 is running on thr: 29376 Task 6 is running on thr: 36304 Task 4 is running on thr: 31416 🐢🐢🐢 1 🐉🐉🐉 Task 9 is running on thr: 29376 🐢🐢🐢 0 🐉🐉🐉 Task 8 is running on thr: 6900 🐢🐢🐢 2 🐉🐉🐉 🐢🐢🐢 6 🐉🐉🐉 🐢🐢🐢 4 🐉🐉🐉 🐢🐢🐢 5 🐉🐉🐉 🐢🐢🐢 3 🐉🐉🐉 🐢🐢🐢 7 🐉🐉🐉 🐢🐢🐢 8 🐉🐉🐉 🐢🐢🐢 9 🐉🐉🐉 sum: 90 它支持任意可调用类型，当然也包括非静态成员函数。我们使用了 std::decay_t，所以参数的传递其实是按值复制，而不是引用传递，这一点和大部分库的设计一致。示例如下： struct X { void f(const int\u0026 n) const { std::osyncstream{ std::cout } \u003c\u003c \u0026n \u003c\u003c '\\n'; } }; int main() { ThreadPool pool{ 4 }; // 创建一个有 4 个线程的线程池 X x; int n = 6; std::cout \u003c\u003c \u0026n \u003c\u003c '\\n'; auto t = pool.submit(\u0026X::f, \u0026x, n); // 默认复制，地址不同 auto t2 = pool.submit(\u0026X::f, \u0026x, std::ref(n)); t.wait(); t2.wait(); } // 析构自动 stop() 我们的线程池的 submit 成员函数在传递参数的行为上，与先前介绍的 std::thread 和 std::async 等设施基本一致。 构造函数和析构函数： 构造函数：初始化线程池并启动线程。 析构函数：停止线程池并等待所有线程结束。 外部接口： stop()：停止线程池，通知所有线程退出（不会等待所有任务执行完毕）。 submit()：将任务提交到任务","date":"2025-03-24","objectID":"/2025/80f2e62/:2:2","tags":["C++"],"title":"并发编程（三）","uri":"/2025/80f2e62/"},{"categories":["八股"],"content":"《现代C++并发编程教程》 —— C++并发编程学习笔记（二） ","date":"2025-03-24","objectID":"/2025/4b155bd/:0:0","tags":["C++"],"title":"并发编程（二）","uri":"/2025/4b155bd/"},{"categories":["八股"],"content":"等待事件或条件 假设你正在一辆夜间运行的地铁上，那么你要如何在正确的站点下车呢？ 1.一直不休息，每一站都能知道，这样就不会错过你要下车的站点，但是这会很疲惫。 这种方法被称为“忙等待（busy waiting）”也称 “自旋“。 bool flag = false; std::mutex m; void wait_for_flag() { std::unique_lock\u003cstd::mutex\u003e lk{ m }; while (!flag){ lk.unlock(); // 1 解锁互斥量 lk.lock(); // 2 上锁互斥量 } } 2.可以看一下时间，估算一下地铁到达目的地的时间，然后设置一个稍早的闹钟，就休息。这个方法听起来还行，但是你可能被过早的叫醒，甚至估算错误导致坐过站，又或者闹钟没电了睡过站。 第二种方法就是加个延时，这种实现进步了很多，减少浪费的执行时间，但很难确定正确的休眠时间。这会影响到程序的行为，在需要快速响应的程序中就意味着丢帧或错过了一个时间片。循环中，休眠 ② 前函数对互斥量解锁 ①，再休眠结束后再对互斥量上锁，让另外的线程有机会获取锁并设置标识（因为修改函数和等待函数共用一个互斥量）。 void wait_for_flag() { std::unique_lock\u003cstd::mutex\u003e lk{ m }; while (!flag){ lk.unlock(); // 1 解锁互斥量 std::this_thread::sleep_for(std::chrono::milliseconds(100)); // 2 休眠 lk.lock(); // 3 上锁互斥量 } } 3.事实上最简单的方式是，到站的时候有人或者其它东西能将你叫醒（比如手机的地图，到达设置的位置就提醒）。 第三种方式（也是最好的）实际上就是使用条件变量了。通过另一线程触发等待事件的机制是最基本的唤醒方式，这种机制就称为“条件变量”。 C++ 标准库对条件变量有两套实现：std::condition_variable 和 std::condition_variable_any，这两个实现都包含在 \u003ccondition_variable\u003e 这个头文件中。 condition_variable_any 类是 std::condition_variable 的泛化。相对于只在 std::unique_lock\u003cstd::mutex\u003e 上工作的 std::condition_variable，condition_variable_any 能在任何满足 可基本锁定(BasicLockable) 要求的锁上工作，所以增加了 _any 后缀。显而易见，这种区分必然是 any 版更加通用但是却有更多的性能开销。所以通常首选 std::condition_variable。有特殊需求，才会考虑 std::condition_variable_any。 std::mutex mtx; // 创建了一个互斥量，用于保护共享数据的访问，确保在多线程环境下的数据同步。 std::condition_variable cv; // 创建了一个条件变量，用于线程间的同步，当条件不满足时，线程可以等待，直到条件满足时被唤醒。 bool arrived = false; // 设置了一个标志位，表示是否到达目的地。 void wait_for_arrival() { std::unique_lock\u003cstd::mutex\u003e lck(mtx); // 使用互斥量创建了一个独占锁。 cv.wait(lck, []{ return arrived; }); // 阻塞当前线程，释放（unlock）锁，直到条件被满足。 std::cout \u003c\u003c \"到达目的地，可以下车了！\" \u003c\u003c std::endl; } void simulate_arrival() { std::this_thread::sleep_for(std::chrono::seconds(5)); // 模拟地铁到站，假设5秒后到达目的地 { std::lock_guard\u003cstd::mutex\u003e lck(mtx); arrived = true; // 设置条件变量为 true，表示到达目的地 } cv.notify_one(); // 通知等待的线程 } 这样，当 simulate_arrival 函数执行后，arrived 被设置为 true，并且通过 cv.notify_one() 唤醒了等待在条件变量上的线程，从而使得 wait_for_arrival 函数中的等待结束，可以执行后续的操作，即输出提示信息。 条件变量的 wait 成员函数有两个版本，以上代码使用的就是第二个版本，传入了一个谓词。 void wait(std::unique_lock\u003cstd::mutex\u003e\u0026 lock); // 1 template\u003cclass Predicate\u003e void wait(std::unique_lock\u003cstd::mutex\u003e\u0026 lock, Predicate pred); // 2 ②等价于： while (!pred()) wait(lock); 第二个版本只是对第一个版本的包装，等待并判断谓词，会调用第一个版本的重载。这可以避免 虚假唤醒 条件变量虚假唤醒是指在使用条件变量进行线程同步时，有时候线程可能会在没有收到通知的情况下被唤醒。问题取决于程序和系统的具体实现。解决方法很简单，在循环中等待并判断条件可一并解决。使用 C++ 标准库则没有这个烦恼了。 ","date":"2025-03-24","objectID":"/2025/4b155bd/:1:0","tags":["C++"],"title":"并发编程（二）","uri":"/2025/4b155bd/"},{"categories":["八股"],"content":"线程安全的队列 这里介绍一个更为复杂的示例，用于巩固条件变量的学习。在实现一个线程安全的队列过程中，需要注意两点内容： 当执行 push 操作时，需要确保没有其他线程正在执行 push 或 pop 操作；同样，在执行 pop 操作时，也需要确保没有其他线程正在执行 push 或 pop 操作。 当队列为空时，不应该执行 pop 操作。因此，我们需要使用条件变量来传递一个谓词，以确保在执行 pop 操作时队列不为空。 以下是一个线程安全的模版类 threadsafe_queue： template\u003ctypename T\u003e class threadsafe_queue { mutable std::mutex m; // 互斥量，用于保护队列操作的独占访问 std::condition_variable data_cond; // 条件变量，用于在队列为空时等待 std::queue\u003cT\u003e data_queue; // 实际存储数据的队列 public: threadsafe_queue() {} // 无参构造 void push(T new_value) { { std::lock_guard\u003cstd::mutex\u003e lk { m }; data_queue.push(new_value); } data_cond.notify_one(); } // 从队列中弹出元素（阻塞直到队列不为空） void pop(T\u0026 value) { std::unique_lock\u003cstd::mutex\u003e lk{ m }; data_cond.wait(lk, [this] {return !data_queue.empty(); }); // 这里的 this 表示按值传递 this，见 lambda 表达式用法 value = data_queue.front(); data_queue.pop(); } // 从队列中弹出元素（阻塞直到队列不为空），并返回一个指向弹出元素的 shared_ptr std::shared_ptr\u003cT\u003e pop() { std::unique_lock\u003cstd::mutex\u003e lk{ m }; data_cond.wait(lk, [this] {return !data_queue.empty(); }); std::shared_ptr\u003cT\u003e res { std::make_shared\u003cT\u003e(data_queue.front()) }; data_queue.pop(); return res; } bool empty()const { std::lock_guard\u003cstd::mutex\u003e lk (m); return data_queue.empty(); } }; ","date":"2025-03-24","objectID":"/2025/4b155bd/:2:0","tags":["C++"],"title":"并发编程（二）","uri":"/2025/4b155bd/"},{"categories":["八股"],"content":"使用 future 举个例子，我们在车站等车，你可能会做一些别的事情打发时间，比如学习现代C++并发编程教程、玩手机等，但始终在等待一件事情：车到站。 C++ 标准库将这种事件称为 future。它用于处理线程中需要等待某个事件的情况，线程知道预期结果。等待的同时也可以执行其它的任务。 C++ 标准库有两种 future，都声明在 \u003cfuture\u003e 头文件中：独占的 std::future 、共享的 std::shared_future。它们的区别与 std::unique_ptr 和 std::shared_ptr 类似。std::future 只能与单个指定事件关联，而 std::shared_future 能关联多个事件。它们都是模板，它们的模板类型参数，就是其关联的事件（函数）的返回类型。当多个线程需要访问一个独立 future 对象时， 必须使用互斥量或类似同步机制进行保护。而多个线程访问同一共享状态，若每个线程都是通过其自身的 shared_future 对象副本进行访问，则是安全的。 最简单有效的使用是，我们先前讲的 std::thread 在线程中执行任务是没有返回值的，这个问题就能使用 future 解决。 ","date":"2025-03-24","objectID":"/2025/4b155bd/:3:0","tags":["C++"],"title":"并发编程（二）","uri":"/2025/4b155bd/"},{"categories":["八股"],"content":"创建异步任务获取返回值 假设需要执行一个耗时任务并获取其返回值，但是并不急切的需要它。那么就可以启动新线程计算，然而 std::thread 没提供直接从线程获取返回值的机制。所以我们可以使用 std::async 函数模板。 使用 std::async 启动一个异步任务，它会返回一个 std::future 对象，这个对象和任务关联，将持有最终计算出来的结果。当需要任务执行完的结果的时候，只需要调用 get() 成员函数，就会阻塞直到 future 为就绪为止（即任务执行完毕），返回执行结果。valid() 成员函数检查 future 当前是否关联共享状态，即是否当前关联任务。还未关联，或者任务已经执行完（调用了 get()、set()），都会返回 false。 #include \u003ciostream\u003e #include \u003cthread\u003e #include \u003cfuture\u003e // 引入 future 头文件 int task(int n) { std::cout \u003c\u003c \"异步任务 ID: \" \u003c\u003c std::this_thread::get_id() \u003c\u003c '\\n'; return n * n; } int main() { std::future\u003cint\u003e future = std::async(task, 10); std::cout \u003c\u003c \"main: \" \u003c\u003c std::this_thread::get_id() \u003c\u003c '\\n'; std::cout \u003c\u003c std::boolalpha \u003c\u003c future.valid() \u003c\u003c '\\n'; // true std::cout \u003c\u003c future.get() \u003c\u003c '\\n'; std::cout \u003c\u003c std::boolalpha \u003c\u003c future.valid() \u003c\u003c '\\n'; // false } 关于 std::async 的参数传递，这里不再展开记录，用时再查。 ","date":"2025-03-24","objectID":"/2025/4b155bd/:3:1","tags":["C++"],"title":"并发编程（二）","uri":"/2025/4b155bd/"},{"categories":["八股"],"content":"信号量 信号量是一个非常轻量简单的同步设施（在 C++ 20中被引入），它维护一个计数，这个计数不能小于 0。信号量提供两种基本操作：释放（增加计数）和等待（减少计数）。如果当前信号量的计数值为 0，那么执行“等待”操作的线程将会一直阻塞，直到计数大于 0，也就是其它线程执行了 “释放” 操作。 C++ 提供了两个信号量类型：std::counting_semaphore 与 std::binary_semaphore，定义在 \u003csemaphore\u003e 中。其中 binary_semaphore 只是 counting_semaphore 的一个特化别名（其 LeastMaxValue 为1，LeastMaxValue 意思是信号量维护的计数最大值。）： using binary_semaphore = counting_semaphore\u003c1\u003e; 举个具体使用信号量的例子： // 全局二元信号量对象 // 设置对象初始计数为 0 std::binary_semaphore smph_signal_main_to_thread{ 0 }; std::binary_semaphore smph_signal_thread_to_main{ 0 }; void thread_proc() { smph_signal_main_to_thread.acquire(); std::cout \u003c\u003c \"[线程] 获得信号\" \u003c\u003c std::endl; std::this_thread::sleep_for(3s); std::cout \u003c\u003c \"[线程] 发送信号\\n\"; smph_signal_thread_to_main.release(); } int main() { std::jthread thr_worker{ thread_proc }; std::cout \u003c\u003c \"[主] 发送信号\\n\"; smph_signal_main_to_thread.release(); smph_signal_thread_to_main.acquire(); std::cout \u003c\u003c \"[主] 获得信号\\n\"; } 结果： [主] 发送信号 [线程] 获得信号 [线程] 发送信号 [主] 获得信号 acquire 函数就是我们先前说的“等待”（原子地减少计数），release 函数就是\"释放\"（原子地增加计数）。 提示 信号量常用于 发信/提醒 而非互斥，通过初始化该信号量为 0 从而阻塞尝试 acquire() 的接收者，直至提醒者通过调用 release(n) “发信”。在此方面可把信号量当作条件变量的替代品，通常它有更好的性能。 假设我们有一个 Web 服务器，它只能处理有限数量的并发请求。为了防止服务器过载，我们可以使用信号量来限制并发请求的数量。 // 定义一个信号量，最大并发数为 3 std::counting_semaphore\u003c3\u003e semaphore{ 3 }; // counting_semaphore 轻量同步原语，允许同一资源进行多个并发的访问，至少允许 LeastMaxValue 个同时访问者 void handle_request(int request_id) { // 请求到达，尝试获取信号量 std::cout \u003c\u003c \"进入 handle_request 尝试获取信号量\\n\"; semaphore.acquire(); std::cout \u003c\u003c \"成功获取信号量\\n\"; // 此处延时三秒可以方便测试，会看到先输出 3 个“成功获取信号量”，因为只有三个线程能成功调用 acquire，剩余的会被阻塞 std::this_thread::sleep_for(3s); // 模拟处理时间 std::random_device rd; std::mt19937 gen{ rd() }; std::uniform_int_distribution\u003c\u003e dis(1, 5); int processing_time = dis(gen); std::this_thread::sleep_for(std::chrono::seconds(processing_time)); std::cout \u003c\u003c std::format(\"请求 {} 已被处理\\n\", request_id); semaphore.release(); } int main() { // 模拟 10 个并发请求 std::vector\u003cstd::jthread\u003e threads; for (int i = 0; i \u003c 10; ++i) { threads.emplace_back(handle_request, i); } } 牢记信号量的基本的概念不变，计数的值不能小于 0，如果当前信号量的计数值为 0，那么执行 “等待”（acquire） 操作的线程将会一直阻塞。明白这点，那么就都不存在问题。 ","date":"2025-03-24","objectID":"/2025/4b155bd/:4:0","tags":["C++"],"title":"并发编程（二）","uri":"/2025/4b155bd/"},{"categories":["八股"],"content":"《现代C++并发编程教程》 —— C++并发编程学习笔记（一） ","date":"2025-03-23","objectID":"/2025/acc27a1/:0:0","tags":["C++"],"title":"并发编程（一）","uri":"/2025/acc27a1/"},{"categories":["八股"],"content":"启动线程 #include \u003ciostream\u003e #include \u003cthread\u003e void hello() { printf(\"hello world!\\n\"); } int main() { std::thread my_thread(hello); } 可以传入函数对象，如上例所示。也可以传入类或者其他重载了 () （callable）运算符的对象，例如： class task { public: void operator()() const { do_something(); do_something_else(); } }; task f; std::thread my_thread(f); 但这里需要注意一个问题，由于 C++ 的语法问题，有时会造成歧义，例如： std::thread my_thread(task()); // 这会被认为是声明了一个返回值为 thread 的，名为 my_thread 的函数 这里最好使用 {} 运算符来创建一个 thread 对象，如： std::thread my_thread{task()}。同时也可以用匿名函数（lambda表达式）来创建线程： #include \u003ciostream\u003e #include \u003cthread\u003e int main() { std::thread thread{ [] {std::cout \u003c\u003c \"Hello World!\\n\"; } }; thread.join(); } 当一个线程对象创建时（即 std::thread 对象构造时）就开始执行传入的函数 f 了。 ","date":"2025-03-23","objectID":"/2025/acc27a1/:1:0","tags":["C++"],"title":"并发编程（一）","uri":"/2025/acc27a1/"},{"categories":["八股"],"content":"线程管理 启动线程后（构造 std::thread 对象），我们必须在线程的生命周期结束之前，即 std::thread::~thread 调用之前，决定它的执行策略，包括 join() 和 detach()。 ","date":"2025-03-23","objectID":"/2025/acc27a1/:2:0","tags":["C++"],"title":"并发编程（一）","uri":"/2025/acc27a1/"},{"categories":["八股"],"content":"join() 其中 join() 表示将阻塞关联的线程，直至执行完毕。内部实现会让 std::thread::joinable() 返回 false。否则会返回 true，执行 std::terminate()。 ","date":"2025-03-23","objectID":"/2025/acc27a1/:2:1","tags":["C++"],"title":"并发编程（一）","uri":"/2025/acc27a1/"},{"categories":["八股"],"content":"detach() 执行了 detach() 后，表示线程对象放弃了对线程资源的所有权，允许此线程的独立运行，在线程退出时释放所有分配的资源。通常不建议使用 detach()，可以用 join() 替代。 可以提供一个类，RAII（Resource Acquisition Initilization）地确保线程执行完成，线程对象正常析构释放资源： class thread_guard { std::thread\u0026 m_t; public: explicit thread_guard(std::thread\u0026 t) : m_t{ t } {} ~thread_guard() { std::puts(\"析构\"); // 打印日志 不用在乎 if (m_t.joinable()) { // 线程对象当前关联了活跃线程 m_t.join(); } } thread_guard(const thread_guard\u0026) = delete; thread_guard\u0026 operator=(const thread_guard\u0026) = delete; }; void f() { int n = 0; std::thread t{ func{n},10 }; thread_guard g(t); f2(); // 可能抛出异常 } ","date":"2025-03-23","objectID":"/2025/acc27a1/:2:2","tags":["C++"],"title":"并发编程（一）","uri":"/2025/acc27a1/"},{"categories":["八股"],"content":"传递参数 向可调用对象传递参数，只需要将这些参数作为 std::thread 的构造参数即可。 需要注意的是，这些参数会复制到新线程的内存空间中，即使函数中的参数是引用，依然实际是复制。 void f(int, const int\u0026 a); int n = 1; std::thread t{ f, 3, n }; 线程对象 t 的构造没有问题，可以通过编译，但是这个 n 实际上并没有按引用传递，而是按值复制的。如果我们的 f 的形参类型不是 const 的引用，则会产生一个编译错误。可以用标准库的 std::ref、std::cref 函数模版。 void f(int, int\u0026 a) { std::cout \u003c\u003c \u0026a \u003c\u003c '\\n'; } int main() { int n = 1; std::cout \u003c\u003c \u0026n \u003c\u003c '\\n'; std::thread t { f, 3, std::ref(n) }; t.join(); } ","date":"2025-03-23","objectID":"/2025/acc27a1/:3:0","tags":["C++"],"title":"并发编程（一）","uri":"/2025/acc27a1/"},{"categories":["八股"],"content":"共享数据 我们都知道线程通信的方式有临界区、互斥量、信号量、条件变量、读写锁： 临界区：每个线程中访问临界资源的那段代码称为临界区（Critical Section）（临界资源是一次仅允许一个线程使用的共享资源）。每次只准许一个线程进入临界区，进入后不允许其他线程进入。不论是硬件临界资源，还是软件临界资源，多个线程必须互斥地对它进行访问。在临界区中，通常会使用同步机制，比如我们要讲的互斥量（Mutex） 互斥量：采用互斥对象机制，只有拥有互斥对象的线程才可以访问。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。 信号量：计数器，允许多个线程同时访问同一个资源。 条件变量：通过条件变量通知操作的方式来保持多线程同步。 读写锁：读写锁与互斥量类似。但互斥量要么是锁住状态，要么就是不加锁状态。读写锁一次只允许一个线程写，但允许一次多个线程读，这样效率就比互斥锁要高。 如果有以下情况，出现数据竞争情况。 std::vector\u003cint\u003e v; void f() { v.emplace_back(1); } void f2() { v.erase(v.begin()); } int main() { std::thread t{ f }; std::thread t2{ f2 }; t.join(); t2.join(); std::cout \u003c\u003c v.size() \u003c\u003c '\\n'; // 有时出现段错误，有时输出0，不稳定的输出结果 } 这里我们可以用互斥量来解决这一问题。 #include \u003ciostream\u003e #include \u003cmutex\u003e #include \u003cthread\u003e #include \u003cvector\u003e std::mutex m; std::vector\u003cint\u003e v; void f() { m.lock(); v.emplace_back(1); m.unlock(); } void f2() { m.lock(); v.erase(v.begin()); m.unlock(); } int main() { std::thread t{ f }; std::thread t2{ f2 }; t.join(); t2.join(); std::cout \u003c\u003c v.size() \u003c\u003c '\\n'; // 稳定输出0 } 另外一个例子，使用 mutex 互斥量前： void f() { // this_thread::get_id() 表示获取当前线程的唯一标识符，以便在多线程程序中区分不同的线程。 std::cout \u003c\u003c std::this_thread::get_id() \u003c\u003c '\\n'; } int main() { std::vector\u003cstd::thread\u003e threads; for (std::size_t i = 0; i \u003c 10; ++i) threads.emplace_back(f); for (auto\u0026 thread : threads) thread.join(); } 这里有一个点，正好说明一下 push_back() 和 emplace_back() 的区别 如果要用 push_back，则需要先构造一个 thread 临时对象：threads.push_back(std::thread(f)); 而如果用 emplace_back，该方法允许在 vector 末尾直接构造对象，而无需创建临时对象。它接受构造函数的参数，并在适当的位置直接调用构造函数。这样可以减少不必要的对象创建和移动操作，提高性能：threads.emplace_back(f); 使用后： #include \u003cmutex\u003e // 必要标头 std::mutex m; void f() { m.lock(); std::cout \u003c\u003c std::this_thread::get_id() \u003c\u003c '\\n'; m.unlock(); } int main() { std::vector\u003cstd::thread\u003ethreads; for (std::size_t i = 0; i \u003c 10; ++i) threads.emplace_back(f); for (auto\u0026 thread : threads) thread.join(); } 当多个线程执行函数 f 的时候，只有一个线程能成功调用 lock() 给互斥量上锁，其他所有的线程 lock() 的调用将阻塞执行，直至获得锁。第一个调用 lock() 的线程得以继续往下执行，执行我们的 std::cout 输出语句，不会有任何其他的线程打断这个操作。直到线程执行 unlock()，就解锁了互斥量。那么其他线程此时也就能再有一个成功调用 lock。至于是哪个线程才会成功调用，这个是由操作系统调度决定的 这里我理解的是，“锁” 是一种广泛的概念，可以有多种实现方式，c++ 中的互斥量 mutex 可以用来实现锁 ","date":"2025-03-23","objectID":"/2025/acc27a1/:4:0","tags":["C++"],"title":"并发编程（一）","uri":"/2025/acc27a1/"},{"categories":["八股"],"content":"std::lock_guard 一般来说，不建议直接使用互斥量 mutex 显式地进行 lock() 和 unlock()。可以用 C++11 标准引入的管理类 std::lock_guard: void f() { std::lock_guard\u003cstd::mutex\u003e lc{ m }; // 等价于 m.lock()，超出作用域调用析构来 unlock std::cout \u003c\u003c std::this_thread::get_id() \u003c\u003c '\\n'; } std::lock_guard 实现比较简单，可以看它在 MSVC STL 中的实现。 我们要尽可能的让互斥量上锁的粒度小，只用来确保必须的共享资源的线程安全。 “粒度”通常用于描述锁定的范围大小，较小的粒度意味着锁定的范围更小，因此有更好的性能和更少的竞争。 比如有的时候可以看到这样的写法： void f() { //code.. { std::lock_guard\u003cstd::mutex\u003e lc{ m }; // 涉及共享资源的修改的代码... } //code.. } 使用 {} 创建了一个块作用域，限制了对象 lc 的生存期，进入作用域构造 lock_guard 的时候上锁（lock），离开作用域析构的时候解锁（unlock）。 举一个具体的例子： std::mutex m; void add_to_list(int n, std::list\u003cint\u003e\u0026 list) { std::vector\u003cint\u003e numbers(n + 1); std::iota(numbers.begin(), numbers.end(), 0); // iota是对vector进行递增（默认递增1）赋值的方法，0是起始值 int sum = std::accumulate(numbers.begin(), numbers.end(), 0); // 0是起始值 { std::lock_guard\u003cstd::mutex\u003e lc{ m }; list.push_back(sum); } } void print_list(const std::list\u003cint\u003e\u0026 list){ std::lock_guard\u003cstd::mutex\u003e lc{ m }; for(const auto\u0026 i : list){ std::cout \u003c\u003c i \u003c\u003c ' '; } std::cout \u003c\u003c '\\n'; } // ...... // std::list\u003cint\u003e list; std::thread t1{ add_to_list,i,std::ref(list) }; // 上面提到过，传参即使是引用，也会被复制，需要用 std::ref std::thread t2{ add_to_list,i,std::ref(list) }; std::thread t3{ print_list,std::cref(list) }; // const 引用需要用 std::cref std::thread t4{ print_list,std::cref(list) }; t1.join(); t2.join(); t3.join(); t4.join(); 这里的共享数据只有 list， 先看 add_to_list，只有 list.push_back(sum) 涉及到了对共享数据的修改，需要进行保护，因此我们用 {} 包裹。 函数 print_list() 打印 list，给整个函数上锁，同一时刻只能有一个线程执行。我们代码是多个线程执行这两个函数，两个函数共享了一个锁，这样确保了当执行函数 print_list() 打印的时候，list 的状态是确定的。打印函数 print_list 和 add_to_list 函数的修改操作同一时间只能有一个线程在执行。print_list() 不可能看到正在被 add_to_list() 修改的 list。 至于到底哪个函数哪个线程会先执行，执行多少次，这些都由操作系统调度决定，也完全有可能连续 4 次都是执行函数 print_list 的线程成功调用 lock，会打印出了一样的值，这都很正常。 ","date":"2025-03-23","objectID":"/2025/acc27a1/:4:1","tags":["C++"],"title":"并发编程（一）","uri":"/2025/acc27a1/"},{"categories":["八股"],"content":"try_lock try_lock 是互斥量中的一种尝试上锁的方式。与常规的 lock 不同，try_lock 会尝试上锁，但如果锁已经被其他线程占用，则不会阻塞当前线程，而是立即返回。 它的返回类型是 bool ，如果上锁成功就返回 true，失败就返回 false。 这种方法在多线程编程中很有用，特别是在需要保护临界区的同时，又不想线程因为等待锁而阻塞的情况下。 std::mutex mtx; void thread_function(int id) { // 尝试加锁 if (mtx.try_lock()) { std::cout \u003c\u003c \"线程：\" \u003c\u003c id \u003c\u003c \" 获得锁\" \u003c\u003c std::endl; // 临界区代码 std::this_thread::sleep_for(std::chrono::milliseconds(100)); // 模拟临界区操作 mtx.unlock(); // 解锁 std::cout \u003c\u003c \"线程：\" \u003c\u003c id \u003c\u003c \" 释放锁\" \u003c\u003c std::endl; } else { std::cout \u003c\u003c \"线程：\" \u003c\u003c id \u003c\u003c \" 获取锁失败 处理步骤\" \u003c\u003c std::endl; } } 如果有两个线程运行这段代码，必然有一个线程无法成功上锁，要走 else 的分支。 std::thread t1(thread_function, 1); std::thread t2(thread_function, 2); t1.join(); t2.join(); 可能的运行结果： 线程：1 获得锁 线程：2 获取锁失败 处理步骤 线程：1 释放锁 小心 切勿将受保护数据的指针或引用传递到互斥量作用域之外，不然保护将形同虚设。下面是一个具体例子 class Data { int a{}; std::string b{}; public: void do_something() { // 修改数据成员等... } }; class Data_wrapper { Data data; std::mutex m; public: template\u003cclass Func\u003e void process_data(Func func) { std::lock_guard\u003cstd::mutex\u003e lc{m}; func(data); // 受保护数据传递给函数 } }; Data* p = nullptr; void malicious_function(Data\u0026 protected_data) { p = \u0026protected_data; // 受保护的数据被传递到外部 } Data_wrapper d; void foo() { d.process_data(malicious_function); // 传递了一个恶意的函数 p-\u003edo_something(); // 在无保护的情况下访问保护数据 } 成员函数模板 process_data 看起来一点问题也没有，使用 std::lock_guard 对数据做了保护，但是调用方传递了 malicious_function 这样一个恶意的函数，使受保护数据传递给外部，可以在没有被互斥量保护的情况下调用 do_something()。 ","date":"2025-03-23","objectID":"/2025/acc27a1/:4:2","tags":["C++"],"title":"并发编程（一）","uri":"/2025/acc27a1/"},{"categories":["八股"],"content":"死锁：问题与解决 两个线程需要对它们所有的互斥量做一些操作，其中每个线程都有一个互斥量，且等待另一个线程的互斥量解锁。因为它们都在等待对方释放互斥量，没有线程工作。 这种情况就是死锁。一般只有多个互斥量才会遇到死锁问题 避免死锁的一般建议是让两个互斥量以相同的顺序上锁，总在互斥量 B 之前锁住互斥量 A，就通常不会死锁。反面示例： std::mutex m1,m2; std::size_t n{}; void f() { std::lock_guard\u003cstd::mutex\u003e lc1{ m1 }; std::lock_guard\u003cstd::mutex\u003e lc2{ m2 }; ++n; } void f2() { std::lock_guard\u003cstd::mutex\u003e lc1{ m2 }; std::lock_guard\u003cstd::mutex\u003e lc2{ m1 }; ++n; } f 与 f2 因为互斥量上锁顺序不同，就有死锁风险。函数 f 先锁定 m1，然后再尝试锁定 m2，而函数 f2 先锁定 m2 再锁定 m1 。如果两个线程同时运行，它们就可能（具体获得锁的顺序由操作系统调度决定，上面阐述过）会彼此等待对方释放其所需的锁，从而造成死锁。 但有时候即使固定了锁的顺序，依旧会产生问题。当有多个互斥量保护同一个类的对象时，对于相同类型的两个不同对象进行数据的交换操作，为了保证数据交换的正确性，就要避免其它线程修改，确保每个对象的互斥量都锁住自己要保护的区域。如果按照前面的的选择一个固定的顺序上锁解锁，则毫无意义，比如： struct X { X(const std::string\u0026 str) :object{ str } {} friend void swap(X\u0026 lhs, X\u0026 rhs); private: std::string object; std::mutex m; }; void swap(X\u0026 lhs, X\u0026 rhs) { if (\u0026lhs == \u0026rhs) return; std::lock_guard\u003cstd::mutex\u003e lock1{ lhs.m }; std::lock_guard\u003cstd::mutex\u003e lock2{ rhs.m }; swap(lhs.object, rhs.object); } 考虑用户调用的时候将参数交换，就会产生死锁： X a{ \"🤣\" }, b{ \"😅\" }; std::thread t{ [\u0026] {swap(a, b); } }; // 1 std::thread t2{ [\u0026] {swap(b, a); } }; // 2 1 执行的时候，先上锁 a 的互斥量，再上锁 b 的互斥量。 2 执行的时候，先上锁 b 的互斥量，再上锁 a 的互斥量。 完全可能线程 A 执行 1 的时候上锁了 a 的互斥量，线程 B 执行 2 上锁了 b 的互斥量。线程 A 往下执行需要上锁 b 的互斥量，线程 B 则要上锁 a 的互斥量执行完毕才能解锁，哪个都没办法往下执行，死锁。 如何解决？可以使用 C++ 标准库中的 std::lock，它能一次性锁住多个互斥量，并且没有死锁风险。修改后 swap 代码如下： void swap(X\u0026 lhs, X\u0026 rhs) { if (\u0026lhs == \u0026rhs) return; std::lock(lhs.m, rhs.m); // 给两个互斥量上锁 std::lock_guard\u003cstd::mutex\u003e lock1{ lhs.m,std::adopt_lock }; std::lock_guard\u003cstd::mutex\u003e lock2{ rhs.m,std::adopt_lock }; swap(lhs.object, rhs.object); } 因为前面已经使用了 std::lock 上锁，所以后面的 std::lock_guard 构造都额外传递了一个 std::adopt_lock 参数，让其选择到不上锁的构造函数。函数退出也能正常解锁。 std::lock 给 lhs.m 或 rhs.m 上锁时若抛出异常，则在重抛前对任何已锁的对象调用 unlock() 解锁，也就是 std::lock 要么将互斥量都上锁，要么一个都不锁。 C++17 新增了 std::scoped_lock ，提供此函数的 RAII 包装，通常它比裸调用 std::lock 更好。 所以我们前面的代码可以改写为： void swap(X\u0026 lhs, X\u0026 rhs) { if (\u0026lhs == \u0026rhs) return; std::scoped_lock guard{ lhs.m,rhs.m }; swap(lhs.object, rhs.object); } 使用 std::scoped_lock 可以将所有 std::lock 替换掉，减少错误发生。也可以用 std::unique_lock（可以简单理解为 std::lock_guard 的升级版，具有额外的功能，为更复杂的锁做准备），详情见标准库文档。 总结，避免死锁要注意： 避免嵌套锁：线程获取一个锁时，就别再获取第二个锁。每个线程只持有一个锁，自然不会产生死锁。如果必须要获取多个锁，使用 std::lock。 避免在持有锁时调用外部代码 使用固定顺序获取锁 ","date":"2025-03-23","objectID":"/2025/acc27a1/:5:0","tags":["C++"],"title":"并发编程（一）","uri":"/2025/acc27a1/"},{"categories":["八股"],"content":"读写锁 如果需要多线程读取写（多线程读不存在数据竞争；而写和读共存时存在竞争），使用 std::mutex 开销较大。这时可以用专门的读写锁，即 std::shared_timed_mutex (C++ 14)，std::shared_mutex (C++ 17)。示例代码： class Settings { private: std::map\u003cstd::string, std::string\u003e data_; mutable std::shared_mutex mutex_; // “M\u0026M 规则”：mutable 与 mutex 一起出现 public: void set(const std::string\u0026 key, const std::string\u0026 value) { std::lock_guard\u003cstd::shared_mutex\u003e lock{ mutex_ }; data_[key] = value; } std::string get(const std::string\u0026 key) const { std::shared_lock\u003cstd::shared_mutex\u003e lock(mutex_); auto it = data_.find(key); return (it != data_.end()) ? it-\u003esecond : \"\"; // 如果没有找到键返回空字符串 } }; ","date":"2025-03-23","objectID":"/2025/acc27a1/:6:0","tags":["C++"],"title":"并发编程（一）","uri":"/2025/acc27a1/"},{"categories":["八股"],"content":"使用互斥量实现并发读写锁（字节 DataAML 一面手撕题） 我们知道，写操作是独占的；而读操作是非独占的，即多个线程可以同时读。如果多线程访问某个共享变量时，每次访问时都加上一个互斥锁，这样开销会非常大。 所以我们期望在多个线程试图读取共享变量的时候，它们可以立刻获取因为读而加的锁，而不是需要等待前一个线程释放。当然，如果一个线程用写锁锁住了临界区，那么其他线程无论是读还是写都会发生阻塞。 #include \u003ciostream\u003e #include \u003cmutex\u003e #include \u003cthread\u003e class ReadWriteLock { private: std::mutex readMutex; // 用于保护读操作计数器的互斥量 std::mutex writeMutex; // 用于保护写操作的互斥量 int readCount = 0; // 记录当前正在进行读操作的线程数量 bool writing = false; // 表示当前是否有线程正在进行写操作 public: void readLock() { // 锁定读操作互斥量 std::unique_lock\u003cstd::mutex\u003e readLock(readMutex); // 增加读操作计数器 ++ readCount; // 等待没有写操作时进行读操作 while (writing) { readLock.unlock(); std::this_thread::yield(); // 让出CPU，避免忙等待 readLock.lock(); } } void readUnlock() { // 锁定读操作互斥量并减少读操作计数器 std::lock_guard\u003cstd::mutex\u003e readLock(readMutex); -- readCount; } void writeLock() { // 锁定写操作互斥量 std::unique_lock\u003cstd::mutex\u003e writeLock(writeMutex); // 等待没有读操作和写操作时进行写操作 while (readCount \u003e 0 || writing) { writeLock.unlock(); std::this_thread::yield(); // 让出CPU，避免忙等待 writeLock.lock(); } // 标记正在进行写操作 writing = true; } void writeUnlock() { // 锁定写操作互斥量并标记写操作完成 std::lock_guard\u003cstd::mutex\u003e writeLock(writeMutex); writing = false; } }; // 示例使用 int sharedData = 0; ReadWriteLock lock; void reader() { lock.readLock(); std::cout \u003c\u003c \"Reading: \" \u003c\u003c sharedData \u003c\u003c std::endl; lock.readUnlock(); } void writer() { lock.writeLock(); ++ sharedData; std::cout \u003c\u003c \"Writing: \" \u003c\u003c sharedData \u003c\u003c std::endl; lock.writeUnlock(); } int main() { std::thread readers[5]; std::thread writers[3]; // 创建多个读线程和写线程 for (int i = 0; i \u003c 5; ++i) { readers[i] = std::thread(reader); } for (int i = 0; i \u003c 3; ++i) { writers[i] = std::thread(writer); } // 等待所有线程执行完毕 for (auto\u0026 reader : readers) { reader.join(); } for (auto\u0026 writer : writers) { writer.join(); } return 0; } 这段代码中，锁定操作用的是 std::unique_lock，而解锁操作用的是 std::lock_guard。这两者都是 C++ 11 引入的 RAII 包装。正如上面所述，unique_lock 是 lock_guard 的升级版 （更灵活，常与条件变量的 wait()、notify_one()、notify_all()配合使用），这里锁定时需要解锁和重新锁定互斥量。这对于需要在等待条件满足时解锁互斥量并让出 CPU 的场景非常有用。 ","date":"2025-03-23","objectID":"/2025/acc27a1/:6:1","tags":["C++"],"title":"并发编程（一）","uri":"/2025/acc27a1/"},{"categories":["八股"],"content":"介绍 C++ 中的内存分配、管理以及智能指针的原理及使用 ","date":"2025-03-23","objectID":"/2025/01dc872/:0:0","tags":["C++"],"title":"内存分配","uri":"/2025/01dc872/"},{"categories":["八股"],"content":"C++ 中内存的管理 ","date":"2025-03-23","objectID":"/2025/01dc872/:1:0","tags":["C++"],"title":"内存分配","uri":"/2025/01dc872/"},{"categories":["八股"],"content":"程序地址空间 C++ 中，内存分布分为五块区域，分别是：栈；堆；全局变量和静态变量（存放于 data 段和 bss 段）；常量；代码； 上图是内核和用户的虚拟地址空间分布情况，其中，局部变量和参数等都存放在栈中，这部分空间由系统进行管理；而堆中空间主要是用于用户调用 new或 malloc 时分配的空间。这部分区域由用户管理，因此容易造成内存泄漏。 malloc 底层实现原理 step1：从内存池中分配。若所需要内存 \u003c 128KB，则从内存池中尝试分配。若无，则进行 brk 系统调用，从堆上申请内存。 step2：若 \u003e 128KB，不看内存池，直接使用 mmap 系统调用，从文件映射区（同时还存放动态库）中获得内存。 这里我觉得这种虚拟地址空间划分方式粒度太粗，不足以说明具体情况 ","date":"2025-03-23","objectID":"/2025/01dc872/:1:1","tags":["C++"],"title":"内存分配","uri":"/2025/01dc872/"},{"categories":["八股"],"content":"智能指针 智能指针分为三类：shared_ptr，unique_ptr，weak_ptr（c98还引入了 auto_ptr，但已在 c++11中被废弃） unique_ptr unique_ptr 表示专属所有权，用 unique_ptr 管理的内存，只能被一个对象持有。故不支持复制和赋值。 auto w = std::make_unique\u003cWidget\u003e(); // 在 c++14 中，可以用 make_unique 方法来构造。 auto w2 = w; // 编译错误 因此只能通过移动来更改专属所有权： auto w = std::make_unique\u003cWidget\u003e(); auto w2 = std::move(w); // w2 获得内存所有权，w 此时等于 nullptr 用法：需要引入头文件 \u003cmemory\u003e，可以使用右值拷贝构造或 make 方法来构造指针。 unique_ptr\u003cint\u003e p1 = make_unique\u003cint\u003e(100); unique_ptr\u003cstring\u003e ps1(new string(\"good luck\")); 适用场景 忘记 delete class Box { public: Box() : w(new Widget()) {} ~Box() { // 析构函数中忘记 delete w } private: Widget* w; }; 异常安全 void process() { Widget* w = new Widget(); w-\u003edo_something(); // 如果发生异常，那么 delete w 将不会执行，此时就会发生内存泄露 delete w; // 也可以用 try...catch 块捕捉异常，并在 catch 语句中 delete，但是不太美观 + 容易漏写 } shared_ptr shared_ptr 代表的是共享所有权，即多个 shared_ptr 可以共享同一块内存。shared_ptr 内部是利用引用计数来实现内存的自动管理，每当复制一个 shared_ptr，引用计数会 + 1。当一个 shared_ptr 离开作用域时，引用计数会 - 1。当引用计数为 0 的时候，则 delete 内存。 auto w = std::make_shared\u003cWidget\u003e(); auto w2 = w; cout \u003c\u003c w.use_count() \u003c\u003c endl; // g++ -std=c++11 main main.cc output-\u003e2 同时，shared_ptr 也支持移动。从语义上来看，移动指的是所有权的传递。如下： auto w = std::make_shared\u003cWidget\u003e(); auto w2 = std::move(w); // 此时 w 等于 nullptr，w2.use_count() 等于 1 注意 shared_ptr 性能开销更大，几乎是 unique_ptr 的两倍（因为还要维护一个计数） 考虑到线程安全问题，引用计数的增减必须是原子操作。而原子操作一般情况下都比非原子操作慢 使用移动优化性能，尽量使用 std::move 来将 shared_ptr 转移给新对象。因为移动不用增加引用计数，性能更好 使用场景：通常用于指定，有可能多个对象同时管理一个内存的时候。 weak_ptr weak_ptr 是为了解决 shared_ptr 双向引用的问题。即： class B; struct A { shared_ptr\u003cB\u003e b; }; struct B { shared_ptr\u003cA\u003e a; }; auto pa = make_shared\u003cA\u003e(); auto pb = make_shared\u003cB\u003e(); pa-\u003eb = pb; pb-\u003ea = pa; pa 和 pb 存在着循环引用，根据 shared_ptr 引用计数的原理，pa 和 pb 都无法被正常的释放。 对于这种情况, 我们可以使用 weak_ptr： class B; struct A { shared_ptr\u003cB\u003e b; }; struct B { weak_ptr\u003cA\u003e a; }; auto pa = make_shared\u003cA\u003e(); auto pb = make_shared\u003cB\u003e(); pa-\u003eb = pb; pb-\u003ea = pa; weak_ptr 不会增加引用计数，因此可以打破 shared_ptr 的循环引用。 通常做法是 parent 类持有 child 的 shared_ptr, child 持有指向 parent 的 weak_ptr。这样也更符合语义。 ","date":"2025-03-23","objectID":"/2025/01dc872/:1:2","tags":["C++"],"title":"内存分配","uri":"/2025/01dc872/"},{"categories":["八股"],"content":"实现过程 鉴于看到面经中有同学被问到过智能指针的底层实现，因此这里给出两种智能指针（weak_ptr略）的简单实现方式。 Tips this 本身是一个指针，指向该类实例化后的对象本身；*this表示解引用，C++中对一个指针进行解引用，得到的是当前对象的引用，也就是对象本身 注意这里 (*this-\u003e_count) ++ 的用法 注意这里 = delete 的语法，用于显示地禁用特定的函数 shared_ptr： template\u003ctypename T\u003e class shared_ptr { private: T* _ptr; int* _count; // 引用计数 public: // 构造函数 shared_ptr(T* ptr = nullptr) : _ptr(ptr) { if (_ptr) _count = new int(1); else _count = new int(10); } // 拷贝构造 shared_ptr(const shared_ptr\u0026 ptr) { if (this != ptr) { this-\u003e_ptr = ptr._ptr; this-\u003e_count = ptr._count; (*this-\u003e_count) ++ ; } } // 重载operator= shared_ptr\u0026 operator=(const shared_ptr \u0026 ptr) { if (this-\u003e_ptr == ptr._ptr) { return *this; } if (this-\u003e_ptr) { (*this-\u003e_count) -- ; if (*this-\u003e_count == 0) { delete this-\u003e_ptr; delete this-\u003e_count; } } this-\u003e_ptr = ptr._ptr; this-\u003e_count = ptr._count; (*this-\u003e_count) ++ ; return *this; } // operator*重载 T\u0026 operator*() { if (this-\u003e_ptr) { return *(this-\u003e_ptr); } } // operator-\u003e重载 T* operator-\u003e() { if (this-\u003e_ptr) { return this-\u003e_ptr; } } // 析构函数 ~shared_ptr() { (*this-\u003e_count) -- ; if (*this-\u003e_count == 0) { delete this-\u003e_ptr; delete this-\u003e_count; } } // 返回引用计数 int use_count() { return *this-\u003e_count; } }; unique_ptr： template\u003ctypename T\u003e class unique_ptr { private: T* _ptr; public: // 构造函数 unique_ptr(T* ptr = nullptr) : _ptr(ptr) {} // 析构函数 ~unique_ptr() { del() }; // 先释放资源（如果持有），再持有资源 void reset(T* ptr) { del(); _ptr = ptr; } // 返回资源，资源的释放由调用方处理 T* release() { T* ptr = _ptr; _ptr = nullptr; return ptr; } // 获取资源，调用方应该只使用不释放，否则会两次delete资源 T* get() { return _ptr; } private: // 释放 void del() { if (_ptr == nullptr) return; delete _ptr; _ptr = nullptr; } // 禁用拷贝构造 unique_ptr(const unique_ptr \u0026) = delete; // 禁用拷贝赋值 unique_ptr\u0026 operator = (const unique_ptr \u0026) = delete; }; ","date":"2025-03-23","objectID":"/2025/01dc872/:1:3","tags":["C++"],"title":"内存分配","uri":"/2025/01dc872/"},{"categories":["八股"],"content":"C++多态的实现方法及原理 ","date":"2025-03-23","objectID":"/2025/b97727d/:0:0","tags":["C++"],"title":"虚函数与多态","uri":"/2025/b97727d/"},{"categories":["八股"],"content":"虚函数 https://zhuanlan.zhihu.com/p/54145222 https://zhuanlan.zhihu.com/p/629281871 ","date":"2025-03-23","objectID":"/2025/b97727d/:1:0","tags":["C++"],"title":"虚函数与多态","uri":"/2025/b97727d/"},{"categories":["八股"],"content":"概念解释 用一个例子理解虚函数的作用： Animal* catAnimal = \u0026cat Animal\u0026 dogAnimal = dog; catAnimal-\u003espeak() dogAnimal.speak() // 调用的还是基类 Animal 本身的方法 // 为什么要用基类指针或引用来完成？基类能够动态确定其实际所指向的派生类对象，并调用合适版本的方法， // 那么一个函数就可以解决上面的问题 // 用虚函数来完成上述功能 class Animal { public: // ... // virtual string speak() const { return \"???\"; } } class Cat { public: // ... // virtual string speak() const { return \"Meow\"; } } class Dog { public: // ... // virtual string speak() const { return \"Woof\"; } } Animal 类被 Cat 和 Dog类继承并覆盖了 speak 函数以实现不同的行为。当使用 Animal的指针或引用来调用 speak 函数时，会根据运行时的对象类型来动态地决定调用哪个子类的函数，从而实现多态性。 ","date":"2025-03-23","objectID":"/2025/b97727d/:1:1","tags":["C++"],"title":"虚函数与多态","uri":"/2025/b97727d/"},{"categories":["八股"],"content":"实现原理 C++ 中，虚函数的实现原理基于两个概念：虚函数表和虚函数指针。 虚函数表 每个包含虚函数的类，都会生成一个虚函数表（Virtual Table），存储着该类中所有的虚函数的地址。虚函数表是一个由指针构成的数组，每个指针指向一个虚函数的实现代码。 虚函数指针 在对象内存布局中，编译器会添加一个额外的指针，称为虚函数指针或虚表指针（Virtual Table Pointer，a.k.a VTable指针）。这个指针指向该对象对应的虚函数表，从而让程序能够动态地调用正确的虚函数。 虚函数指针可以类比操作系统中，虚拟内存映射中的页表基址，存储在页表基址寄存器（xv6 是 satp 寄存器）中，有了页表基址，就可以找到一级页表，从而找到二级页表，进而找到物理地址。 当一个基类指针或引用调用虚函数时，编译器会使用虚表指针来查找该对象对应的虚函数表，并根据函数在虚函数表中的位置来调用正确的虚函数。但同时由于虚函数表的存在，导致需要额外的存储空间来存储虚函数表及其指针，导致 C++ 在调用虚函数时比其他语言成本要高。 虚函数指针是实现多级继承的关键，在多级继承中，每个子类都需要维护自己的虚函数表及其虚函数指针 虚函数的调用过程 在编译期间，编译器会根据函数调用的类型和对象的类型确定要调用的函数。 在运行期间，程序会根据对象的实际类型来决定调用哪个函数。这个过程叫做动态绑定或者后期绑定。 程序通过虚函数表（vtable）来实现动态绑定。每个含有虚函数的类都有自己的虚函数表，存储了指向实际函数地址的指针。在对象被创建时，它的指针会指向所属类的虚函数表。 当调用虚函数时，在对象中存储的指针会被解引用，获取到虚函数表的地址。然后根据函数调用的类型，从虚函数表中获取相应的函数地址。 最后，程序跳转到函数地址处执行实际的代码。由于是动态绑定，所以调用的函数是根据对象实际类型来决定的。 ","date":"2025-03-23","objectID":"/2025/b97727d/:1:2","tags":["C++"],"title":"虚函数与多态","uri":"/2025/b97727d/"},{"categories":["八股"],"content":"虚函数的使用 在 C++ 中，派生类可以重写 (override) 它继承的虚函数，这被称为函数的覆盖 (overriding)。当然，子类也可以选择不重写基类的虚函数，那么它将默认继承基类的实现，这就是虚函数的重载 (overloading)。 class Base { public: virtual void foo() { std::cout \u003c\u003c \"Base::foo()\" \u003c\u003c std::endl; } }; class Derived : public Base { public: void foo() { std::cout \u003c\u003c \"Derived::foo()\" \u003c\u003c std::endl; } }; int main() { Derived obj; Base* ptr = \u0026obj; ptr-\u003efoo(); // 输出：Derived::foo() return 0; } 可以看到，不论是基类版本还是派生类版本，我们都在函数前面使用了 virtual 关键字，事实上，派生类中的 virtual 关键字并不是必要的。一旦基类中的方法打上了 virtual 标签，那么派生类中匹配的函数也是虚函数。但是，还是建议在后面的派生类中加上 virtual 关键字，作为虚函数的一种提醒，以便后面可能还会有更远的派生。 子类中重写虚函数时，访问权限不能更严格（即不能由 public 变为 private 或 protected），否则编译器会报错； 虚函数的覆盖实际上是通过指定 override 关键字显示声明来实现的。例如： class Base { public: virtual void foo() { std::cout \u003c\u003c \"Base::foo()\" \u003c\u003c std::endl; } }; class Derived : public Base { public: void foo() override { std::cout \u003c\u003c \"Derived::foo()\" \u003c\u003c std::endl; } }; int main() { Derived obj; Base* ptr = \u0026obj; ptr-\u003efoo(); // 输出：Derived::foo() return 0; } 进一步地，一般来说派生类需要重写基类的方法，以便于用基类指针动态调用不同派生类的成员方法，但是一旦函数签名不同，就会导致重写失败。为了避免可能发生的小错误导致重写失败无法调用派生类的成员方法，需要在派生类的成员方法后添加 override： class Super { public: virtual string getName1(int x) { return \"Super\"; } virtual string getName2(int x) { return \"Super\"; } }; class Sub: public Super{ public: virtual string getName1(double x) override { return \"Sub\"; } virtual string getName2(int x) const override { return \"Sub\"; }// 此时无法编译 }; ","date":"2025-03-23","objectID":"/2025/b97727d/:1:3","tags":["C++"],"title":"虚函数与多态","uri":"/2025/b97727d/"},{"categories":["八股"],"content":"纯虚函数 纯虚函数是指在基类中定义的，没有实现的虚函数。这里的 “=0” 表示该函数为虚函数。 virtual void func() = 0; 纯虚函数的作用是让子类必须实现该函数，并且不能直接创建该类的对象（即该类为抽象类）。 抽象类是包含纯虚函数的类，它们不能被实例化，只能被继承。 抽象类只能用作其他类的基类。如果一个类继承了抽象类，则必须实现所有的纯虚函数，否则该类也会成为抽象类。 示例代码： class Shape{ public: // 纯虚函数 virtual double getArea() = 0; }; // 继承自抽象类Shape class Rectangle: public Shape { public: double width; double height; double getArea() {return width * height;} }; // 继承自抽象类Shape class Circle: public Shape { public: double radius; double getArea() {return 3.14*radius*radius;} }; ","date":"2025-03-23","objectID":"/2025/b97727d/:2:0","tags":["C++"],"title":"虚函数与多态","uri":"/2025/b97727d/"},{"categories":["八股"],"content":"动态绑定与静态绑定 通过以上描述，我们可以得知虚函数可以用来进行动态绑定（区分于静态绑定）。 // 静态绑定示例 class Shape { public: void draw() { cout \u003c\u003c \"Drawing a shape.\" \u003c\u003c endl; } }; class Circle : public Shape { public: void draw() { cout \u003c\u003c \"Drawing a circle.\" \u003c\u003c endl; } }; int main() { Shape* shapeObj = new Circle(); shapeObj-\u003edraw(); // 编译时期确定方法调用，输出 \"Drawing a shape.\" } // 动态绑定示例 class Shape { public: virtual void draw() { cout \u003c\u003c \"Drawing a shape.\" \u003c\u003c endl; } }; class Circle : public Shape { public: void draw() { cout \u003c\u003c \"Drawing a circle.\" \u003c\u003c endl; } }; int main() { Shape* shapeObj = new Circle(); shapeObj-\u003edraw(); // 运行时期确定方法调用，输出 \"Drawing a circle.\" } ","date":"2025-03-23","objectID":"/2025/b97727d/:3:0","tags":["C++"],"title":"虚函数与多态","uri":"/2025/b97727d/"},{"categories":["八股"],"content":"静态多态与动态多态 静态多态（也称为编译时多态）是指在编译时就能够确定函数或方法的调用对象，即函数或方法的重载。在静态多态中，函数或方法的重载是通过参数类型、参数数量或参数顺序来区分的。 int add(int a, int b){ return a + b; } double add(double a, double b){ return a + b; } 当调用 add() 方法时，编译器会根据传递给方法的参数类型来决定使用哪个重载版本。 动态多态（也称为运行时多态）是指在程序运行时才能确定函数或方法的调用对象，即虚函数或抽象类。在动态多态中，函数或方法的重载是通过继承和多态来实现的。见上面的虚函数代码样例。 ","date":"2025-03-23","objectID":"/2025/b97727d/:4:0","tags":["C++"],"title":"虚函数与多态","uri":"/2025/b97727d/"},{"categories":["八股"],"content":"一些常见问题 ","date":"2025-03-23","objectID":"/2025/b97727d/:5:0","tags":["C++"],"title":"虚函数与多态","uri":"/2025/b97727d/"},{"categories":["八股"],"content":"虚析构函数 我们知道析构函数存在的必要性之一就是，如果类内有指针类型变量，需要在析构函数中进行手动释放（delete ptr）。但是如果用基类指针指向子类对象，当子类实例被删除时，只会调用基类的析构函数，而不会调用子类的析构函数，从而使得子类中动态分配的内存无法被释放造成内存泄漏。这个时候需要使用虚析构函数来释放内存。 ","date":"2025-03-23","objectID":"/2025/b97727d/:5:1","tags":["C++"],"title":"虚函数与多态","uri":"/2025/b97727d/"},{"categories":["八股"],"content":"虚函数的性能影响 根据上面所述，使用虚函数能够达到动态绑定的目的，这同时会增加一些开销，降低执行效率。但是现代编译器能够将开销优化至可以忽略不计。 ","date":"2025-03-23","objectID":"/2025/b97727d/:5:2","tags":["C++"],"title":"虚函数与多态","uri":"/2025/b97727d/"},{"categories":["八股"],"content":"多重继承中的虚函数 class Base1 { public: virtual void func() { cout \u003c\u003c \"Base1::func()\" \u003c\u003c endl; } }; class Base2 { public: virtual void func() { cout \u003c\u003c \"Base2::func()\" \u003c\u003c endl; } }; class Derived : public Base1, public Base2 { public: virtual void func() { Base1::func(); Base2::func(); } }; 一个类同时继承多个基类，并且这些基类中有多个同名虚函数，那么子类中必须对这些虚函数进行重写。 我理解是，如果是单继承，那么可以重写也可以不重写，不重写相当于就是继承基类的实现；而多继承中为了避免未知的错误，必须对每个基类虚函数进行重写。 ","date":"2025-03-23","objectID":"/2025/b97727d/:5:3","tags":["C++"],"title":"虚函数与多态","uri":"/2025/b97727d/"},{"categories":["算法"],"content":"由 randA() 实现 randB()：万能构造法 randA() 构造 randB() 时，需要找一个最大质因子不超过 A 的数 n (n\u003e=B），然后对 n 分解质因子就能找到每个采样需要取多少种结果。实际到具体数字时，可以把部分质因子合并成不超过 A 的数，从而减少采样次数。 举个具体例子，如何用 rand7() 来构造 rand10() ","date":"2025-03-22","objectID":"/2025/b44918a/:0:0","tags":["构造"],"title":"构造 RandX()","uri":"/2025/b44918a/"},{"categories":["算法"],"content":"确定采样参数 步骤 1：选择一个合适的数 n 我们选择 n = 30，因为它大于或等于 10，并且它的最大质因子是 5，不超过 7。 步骤 2：对 n 进行质因子分解 将 30 分解为质因子的乘积形式： $$ 30 = 21 \\times 31 \\times 5^1 $$ 步骤 3：确定采样次数和结果数量 根据质因子分解的结果，我们需要进行 3 次采样，每次采样的结果数量分别为 2、3 和 5。（分别对应三个质因子） ","date":"2025-03-22","objectID":"/2025/b44918a/:1:0","tags":["构造"],"title":"构造 RandX()","uri":"/2025/b44918a/"},{"categories":["算法"],"content":"进行采样 我们将进行 3 次采样，每次采样使用 rand7() 函数来生成一个介于 1 和 7 之间的随机数。 第一次采样 使用 rand7() 来生成一个随机数，如果结果在 [1, 2] 范围内，则将其作为第一次采样的结果。否则，重新采样。 int first; while (true) { first = rand7(); if (first \u003c= 2) break; } 第二次采样 使用 rand7() 来生成一个随机数，如果结果在 [1, 3] 范围内，则将其作为第一次采样的结果。否则，重新采样。 int second; while (true) { second = rand7(); if (second \u003c= 3) break; } 第三次采样 使用 rand7() 来生成一个随机数，如果结果在 [1, 5] 范围内，则将其作为第一次采样的结果。否则，重新采样。 int third; while (true) { third = rand7(); if (third \u003c= 5) break; } ","date":"2025-03-22","objectID":"/2025/b44918a/:2:0","tags":["构造"],"title":"构造 RandX()","uri":"/2025/b44918a/"},{"categories":["算法"],"content":"组合结果 将每次采样的结果组合起来，得到一个长度为 30 的序列。具体来说： first 的取值范围是 [1, 2]，总共有 2 种可能。 second 的取值范围是 [1, 3]，总共有 3 种可能。 third 的取值范围是 [1, 5]，总共有 5 种可能。 我们通过三次采样得到三个值：first、second 和 third。我们的目标是将这三个值组合成一个唯一的索引，这个索引应该对应于一个长度为 30 的序列中的一个位置。 这三个值的所有可能组合数是：$ 2\\times 3\\times 5 = 30 $， 这正好等于我们预定义的序列长度。 ","date":"2025-03-22","objectID":"/2025/b44918a/:3:0","tags":["构造"],"title":"构造 RandX()","uri":"/2025/b44918a/"},{"categories":["算法"],"content":"映射 为了将这三个值组合成一个唯一的索引，我们需要为每个值分配一个权重，使得它们的组合能够覆盖从 1 到 30 的所有整数。 公式为： $$ index = (first - 1)\\times 3 \\times 5 + (second - 1)\\times 5 + (third - 1) + 1 $$ 代表： $$[0, 1]\\times 3\\times 5 \\rightarrow [0, 15]$$ $$[0, 2]\\times 5 \\rightarrow [0, 10]$$ $$[0, 4] + 1 \\rightarrow [1, 5]$$ ","date":"2025-03-22","objectID":"/2025/b44918a/:4:0","tags":["构造"],"title":"构造 RandX()","uri":"/2025/b44918a/"},{"categories":["算法"],"content":"完整代码 int rand10() { int first, second, third; while (true) { first = rand7(); // 第一次采样 if (first \u003c= 2) break; // 如果结果在 [1, 2] 范围内，则退出循环 } while (true) { second = rand7(); // 第二次采样 if (second \u003c= 3) break; // 如果结果在 [1, 3] 范围内，则退出循环 } while (true) { third = rand7(); // 第三次采样 if (third \u003c= 5) break; // 如果结果在 [1, 5] 范围内，则退出循环 } // 将结果组合并映射到 [1, 10] 范围内 int index = (first - 1) * 3 * 5 + (second - 1) * 5 + (third - 1) + 1; if (index \u003c= 10) return index; else return rand10(); // 如果结果超出范围，则重新采样 } ","date":"2025-03-22","objectID":"/2025/b44918a/:5:0","tags":["构造"],"title":"构造 RandX()","uri":"/2025/b44918a/"},{"categories":["随记"],"content":"建站踩坑过程 ","date":"2025-03-22","objectID":"/2025/b487c0a/:0:0","tags":null,"title":"建站踩坑记录","uri":"/2025/b487c0a/"},{"categories":["随记"],"content":"集成 latex 方法一 ","date":"2025-03-22","objectID":"/2025/b487c0a/:1:0","tags":null,"title":"建站踩坑记录","uri":"/2025/b487c0a/"},{"categories":["随记"],"content":"优秀参考 https://github.com/shuzang/shuzang.github.io ","date":"2025-03-22","objectID":"/2025/b487c0a/:2:0","tags":null,"title":"建站踩坑记录","uri":"/2025/b487c0a/"},{"categories":["随记"],"content":"content 目录位置 移动到左边：https://blog.csdn.net/Xuyiming564445/article/details/122011603 ","date":"2025-03-22","objectID":"/2025/b487c0a/:3:0","tags":null,"title":"建站踩坑记录","uri":"/2025/b487c0a/"},{"categories":["随记"],"content":"评论系统 使用 giscus，将 repo 的discussion 模块用于评论。详情见： http://www.icharm.me/hugo-loveit-using/index.zh_cn.html https://giscus.app/zh-CN ","date":"2025-03-22","objectID":"/2025/b487c0a/:4:0","tags":null,"title":"建站踩坑记录","uri":"/2025/b487c0a/"},{"categories":null,"content":"关于我 MLSys 入门小菜鸡 ","date":"0001-01-01","objectID":"/about/:1:0","tags":null,"title":"关于","uri":"/about/"}]